\chapter{Resultados}\label{cap:resultados}

Foram realizados testes com algumas bases de dados da UCI Machine Learning\footnote{http://archive.ics.uci.edu/ml/}, um repositório de dados a serviço da comunidade de aprendizado de máquina. Criado por estudantes de pós-graduação na UC Irvine em 1987 e até hoje é utilizado não só por estudantes mas também por educadores e pesquisadores como fonte primária de aprendizado de máquina. 

As bases de dados foram escolhidas não só por critérios comparativos de outro trabalho que também já as utilizaram servindo  de referência para os resultados, como também, um cuidado de só escolher bases que estão classificadas, uma vez que esta pesquisa trabalhará com os clusters já formados e não na criação de grupos.

A divisão deste capítulo de resultados iniciará por uma explanação da implementação do trabalho, e logo após, cada base de dados utilizada é destacada em uma seção. A cada seção referente a uma base de dados houve uma divisão de subseções de acordo com os algoritmos utilizados: Naive Bayes e CART.

\section{Implementação}\label{cap:resultados:sec:implement}

Para conseguir gerar os resultados aqui escritos foram feitas implementações utilizando a ferramenta MATLAB\footnote{http://www.mathworks.com/products/matlab/}\footnote{versão: R2016a(9.0.0.341360); 64-bit (glnxa64)}, onde  foi possível utilizar suas funções de aprendizado de máquina já implementadas na Statistics and Machine Learning Toolbox, uma toolbox com implementações preparadas para aprendizado de máquina. Por aprensentar  linguagem técnica e funcões já prontas direcionada para aprendizado de máquina essa ferramenta foi escolhida para colocar em prática essa pesquisa.

Ao longo da pesquisa foram realizados vários testes, porém, nesses testes houveram alterações de algumas variáveis, e métodos de discretização, sempre tentando melhorar os resultados. Essas alterações dependendo da base de dados utilizadas são: variável ''V'', quantidade de faixas ''R'' e métodos de discretização ''EWD,EFD''. 

Como dito na subseção \ref{cap:ferramentas:ssec:algsuper} a variável ${V}$ existe para evitar a ambiguidade dos rótulos, ou seja, quando rótulos apresentarem os mesmos resultados: atributo e faixa de valor. Além de evitar a ambiguidade dos rótulos a variável ${V}$ pode ser utilizada também para selecionar mais de um atributo para ser o rótulo do cluster.

Essa situação é necessária após uma análise da tabela de correlação dos atributos (seção \ref{cap:ferramentas:sec:tecnica}), a exemplo da tabela \ref{tab:matrelevancia:seeds:nb}. E existindo valores muito próximos em relação a outros, e se necessário, utilizar esses atributos também como rótulos, a variável ${V}$ pode ser configurada com um valor que possa abranger esses atributos que possuem valor de porcentagem próximos ao do atributo mais relevante. O valor de ${V}$ é subjetivo e sua adição é condicionada a análise da aplicação do algoritmo na bases de dados.

A composição da tabela de correlação de atributos é o resultado da aplicação do algoritmo enquanto o atributo era a classe da vez, coforme figura \ref{fig:tecnicamodelocomp}, seção \ref{cap:ferramentas:ssec:algsuper}. O atributo de maior valor junto com os atributos da diferença de ${V}$ com o mais relevante, são escolhidos para ser rótulos. Na linha (cluster) 1 o maior valor é o atributo perimetro. Então o valor de perimetro subtraído de ${V=3}$ vai resultar no limete inferior. A partir daí o(s) atributo(s) que possuí(rem) um valor que está entre este resultado, limite inferior, até o de maior porcentagem, irá compor o rótulo.

Na implementação onde é feita a composição da tabela de correlação de atributos é percorrido todos os atributos e a cada iteração um atributo será a saída, ou seja, o atributo classe conforme figura \ref{fig:tecnicamodelocomp}, seção \ref{cap:ferramentas:ssec:algsuper}. A cada iteração um valor da correlação do atributo classe com os demais atributos é gerado compondo a tabela de correlação.

Após a tabela estar montada o atributo rótulo é selecionado a partir do maior valor em relação aos outros atributos, e caso seja necessário também é selecionado como rótulo os atributos que possuam o valor entre a diferença de ${V}$ com o mais relevante. Na linha (cluster) 1 o maior valor é o atributo perimetro. Então o valor de perimetro subtraído de ${V=3}$ vai resultar no limete inferior. A partir daí o(s) atributo(s) que possuí(rem) um valor que está entre este resultado, limite inferior, até o de maior porcentagem, irá compor o rótulo.


A cada base de dados descritas nas seções, são configuradas as variáveis e método de discretização utilizados e implementado dois algoritmos de aprendizado supervisionado com paradigmas diferentes para fazer rotulação. Cada algoritmo terá como resultado um rótulo por cluster de dados servindo de amostra para testar a acurácia.

Os algoritmos utilizados foram o Naive Bayes, subseção \ref{cap:refTeor:sssec:nbayes}, com paradigma estatístico. E também o algoritmo Classification e Regression Trees - CART, subseção \ref{cap:refTeor:sssec:cart}, com paradigma simbólico.

\section{Seeds - Identificação de Tipos de Semente}
Essa base pertence a UCI Machine Learning, composta por sete  atributos definindo suas características e mais um atributo classe  responsável por identificar os tipos de sementes. Em seus atributos  seus valores são todos contínuos e não existem valores em branco,  possuindo um total de 210 registros classificados em três categorias:
\begin{itemize}[noitemsep]
 \item 70 elementos do tipo Kama;
 \item 70 elementos do tipo Rosa;
 \item 70 elementos do tipo Canadian.
\end{itemize}
Para classificar as sementes, como Kama, Rosa e Canadian foi utilizada uma técnica de raio X, que é relativamente mais barata que outras técnicas de imagem, como microscopia ou tecnologia a laser. O material foi colhido de campos expermentais, explorados no Instituo de Agrofísica da Academia Polonês de Ciências em Lublin.

Como já mencionado neste capítulo, seção \ref{cap:resultados:sec:implement}, antes de executar o algoritmo algumas configuração são necessárias. A primeira configuração é o método de discretização do tipo EFD, a segunda é a divisão dos valores dos atributos em faixas, ${R=3}$ para todos os atributos, e também o valor de variação ${V=0\%}$,  não obstante, esta variável ${V}$ só assumirar valor maior que zero após análise dos resultados caso haja ambiguidade.

Na tabela \ref{tab:rot:seeds:nb} e tabela \ref{tab:rot:seeds:cart} são  apresentados os resultados de rotulação dos algoritmo Naive Bayes e CART respectivamente. Essas tabelas são compostas por colunas informando os número dos \textbf{Clusters}, \textbf{Rótulos}  integrando \textbf{Atributo} e sua \textbf{Faixa} de valor. Junto também a coluna \textbf{Relevância} exibindo a resposta do algoritmo de rotulação em porcentagem da correlação do atributo em relação aos outros atributos do cluster, retirado da tabela \ref{tab:matrelevancia:seeds:nb} e da tabela \ref{tab:matrelevancia:seeds:cart} respectivamente. E por último a coluna \textbf{Elem Fora da Faixa} que mostra a quantidade de elementos que não estão dentro da faixa designada pelo do rótulo encontrado.

Essa última coluna, \textbf{Elem Fora da Faixa}, tem a função de exibir, em números, a quantidade de valores que não estão participando da porcentagem da coluna de \textbf{Relevância}. Através de expermentos percebeu-se o mérito de apresentar em números a quantidade de elementos que não estão sendo representados pelo rótulo gerando mais realidade as informações, ao invés de exibir em porcentagem.

\subsection{Naive Bayes} \label{cap:resultados:ssec:seed:nb}
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage[table,xcdraw]{xcolor}
% If you use beamer only pass "xcolor=table" option, i.e. \documentclss[xcolor=table]{beamer}
\begin{table}[!h]
\centering
\caption{Resultado da rotulação com o algoritmo Naive Bayes}
\label{tab:rot:seeds:nb}
\begin{tabular}{llcrc}
\hline
\multicolumn{1}{c}{\cellcolor[HTML]{FFFFFF}} & \multicolumn{2}{c}{Rótulos}                & \multicolumn{1}{r}{}               & \\ \cline{2-3}
Cluster                                      & Atributos      & \multicolumn{1}{c}{Faixa} & \multicolumn{1}{c}{Relevância(\%)} & Elem fora da Faixa\\ \hline \hline
1                                            & area           & ] 12.78 $\sim$  16.14 ]   & 92\%                               & 14\\  \hline
2                                            & area           & ] 16.14 $\sim$  21.18 ]   & 95\%                               & 6\\ \hline
%\multirow{-2}{*}{2}                          & lkernel        & ] 5.826 $\sim$  6.675 ]   & 92\%                               & 6\\  \hline
3                                            & perimetro      & [ 12.41 $\sim$  13.73 ]   & 95\%                               & 5\\ \hline \hline
\end{tabular}
\end{table}



Analisando a coluna Rótulos da tabela \ref{tab:rot:seeds:nb}, nota-se que o atributo \textbf{area} aparece tanto no  cluster 1 como também no cluster 2. A técnica envolve não só o atributo mais relevante, como também, a faixa que os valores mais se repetem dentro do atributo. Nesse caso pode-se observar que o atributo se repete entre os clusters, mas no cluster 1 a faixa de valores difere do cluster 2, sendo considerados rótulos distintos.


Caso os resultados gerados na tabela \ref{tab:matrelevancia:seeds:nb} expusessem clusters com rótulos ambíguos, poderia ser utilizado a variação de ${V}$. Quando houver ambiguidade dos rótulos a seleção dos atributos, que compõem os rótulos, acontecerá da diferença da variável ${V}$ em relação ao atributo de maior relevência do cluster. Caso essa variável tenha o valor alterado, os rótulos dos clusters poderão sofrer mudanças, pois poderia aumentar  ou diminuir o número de atributos dos rótulos, dependendo do valor inserido em ${V}$. Através da tabela \ref{tab:matrelevancia:seeds:nb} é possível analisar todos os valores de relevância gerados para os atributos e analisar qual valor pode-se inserir em ${V}$ para montar o rótulo.

Para exemplificar a utilização da variável ${V}$ pode-se utilizar como exemplo os dados do cluster 2 da tabela \ref{tab:matrelevancia:seeds:nb} e adotando ${V=3\%}$.  Neste exemplo não só o atributo de maior relevância, \textbf{area} com ${95.7\%}$ seria escolhido como rótulo, mas também o atributo \textbf{lkernel} com valor ${92.8\%}$, pois a diferença entre o valor de \textbf{area} com ${V}$ resultaria em ${92.7\%}$. Através dessa diferença todos os atributos que estivessem na faixa de ${92.7\%}$ a  ${95.7\%}$ seriam selecionados como atributos do rótulo.

\begin{table}[!h]
    
    \caption{Resultado da Correlação dos atributos pelo Naive Bayes; Legenda dos Atributos: (A)area, (B)perimetro, (C)compacteness, (D)Lkernel, (E)Wkernel, (F)asymetry, (G)lkgroove}    
    \centering
   \small\addtolength{\tabcolsep}{+2pt}
    \begin{tabular}{|cl|c|c|c|c|c|c|c|}
        \hline \hline
                                &   & \multicolumn{7}{c|}{Atributos}          \\ \cline{3-9} 
        \multicolumn{1}{|l}{}                            &   & A    & B & C & D & E & F & G \\ \hline
        \multicolumn{1}{|c|}{}                           & 1 & 92.8 & 87.1   & 50.0      & 75.7 & 85.7 & 60.0   & 65.7   \\ \cline{2-9} 
        \multicolumn{1}{|c|}{}                           & 2 & 95.7 & 91.4   & 47.1      & 92.8 & 90.0 & 28.5  & 85.7  \\ \cline{2-9} 
        \multicolumn{1}{|c|}{\multirow{-3}{*}{Clusters}} & 3 & 91.4 & 95.7   & 71.4      & 85.7 & 91.4 & 64.2  & 58.5  \\ \hline
    \end{tabular}
    \label{tab:matrelevancia:seeds:nb} 
\end{table}

A tabela \ref{tab:matrelevancia:seeds:nb} é formada por clusters representado pelas linhas, e atributos representado por colunas. Essa tabela é fruto da implementação do Naive Bayes na base de dados \textbf{Seeds}, e foi  gerada para auxiliar a retirada dos atributo(s) rótulo(s). Uma análise pode ser feita através desses dados e ajudar a definir um valor para a variável ${V}$ caso necessário. Percebe-se que algumas características são mais bem correlacionadas que  outras, através de seus valores mais altos. Isso indica o grau de relacionamento entre os atributos após a aplicação do algoritmo. 


\begin{table}[!h]
\caption{Resultado de ${4(quatro)}$ execuções do algoritmo Naive Bayes; Legenda dos Atributos: (A)area, (B)perimetro, (C)compacteness, (D)Lkernel, (E)Wkernel, (F)asymetry, (G)lkgroove}
 \begin{tabular}{ll}
%\rule{0}{50}

  
   %\scalebox{0.5}{%
   \small\addtolength{\tabcolsep}{-5pt}
     \begin{tabular}{|cl|c|c|c|c|c|c|c|}
        \hline \hline
            {\tiny 1a. Execução}     &   & \multicolumn{7}{c|}{Atributos}                                               \\ \cline{3-9} 
       \multicolumn{1}{|l}{}                            &   & A    & B & C & D & E & F & G \\ \hline
        \multicolumn{1}{|c|}{}                           & 1 & 92.8 & 87.1   & 48.5      & 77.1 & 82.8 & 57.1   & 65.7   \\ \cline{2-9} 
        \multicolumn{1}{|c|}{}                           & 2 & 94.2 & 90.0   & 45.7      & 92.8 & 90.0 & 38.5  & 87.1  \\ \cline{2-9} 
        \multicolumn{1}{|c|}{\multirow{-3}{*}{Clusters}} & 3 & 91.4 & 95.7   & 72.8      & 85.7 & 91.4 & 64.2  & 60.0  \\ \hline
      \end{tabular}
    %}
 &
 %\hspace{1cm} %altera o espaçamento entre as tabelas
 
   
 %\scalebox{0.5}{%
   \small\addtolength{\tabcolsep}{-5pt}
   \begin{tabular}{|cl|c|c|c|c|c|c|c|}
        \hline \hline
             {\tiny 2a. Execução }       &   & \multicolumn{7}{c|}{Atributos}                                               \\ \cline{3-9} 
       \multicolumn{1}{|l}{}                            &   & A    & B & C & D & E & F & G \\ \hline
        \multicolumn{1}{|c|}{}                           & 1 & 92.8 & 87.1   & 47.1      & 77.1 & 87.1 & 60.0   & 65.7   \\ \cline{2-9} 
        \multicolumn{1}{|c|}{}                           & 2 & 94.2 & 90.0   & 47.1      & 92.8 & 91.4 & 32.8  & 87.1  \\ \cline{2-9} 
        \multicolumn{1}{|c|}{\multirow{-3}{*}{Clusters}} & 3 & 91.4 & 95.7   & 72.8      & 85.7 & 92.8 & 64.2  & 60.0  \\ \hline
      \end{tabular}
  %}
  \\  [8ex]
 %\hspace{1cm} %altera o espaçamento entre as tabelas
 %\rule{0}{50}
 
 %\scalebox{0.5}{%
   \small\addtolength{\tabcolsep}{-5pt}
   \begin{tabular}{|cl|c|c|c|c|c|c|c|}
        \hline \hline
          {\tiny 3a. Execução}     &   & \multicolumn{7}{c|}{Atributos}                                               \\ \cline{3-9} 
       \multicolumn{1}{|l}{}                            &   & A    & B & C & D & E & F & G \\ \hline
        \multicolumn{1}{|c|}{}                           & 1 & 94.2 & 85.7   & 48.5      & 77.1 & 82.8 & 61.4   & 65.7   \\ \cline{2-9} 
        \multicolumn{1}{|c|}{}                           & 2 & 92.8 & 90.0   & 50.0      & 92.8 & 90.0 & 32.8  & 87.1  \\ \cline{2-9} 
        \multicolumn{1}{|c|}{\multirow{-3}{*}{Clusters}} & 3 & 91.4 & 95.7   & 72.8      & 85.7 & 92.8 & 64.2  & 60.0  \\ \hline
   \end{tabular}
    
    &
    
       \small\addtolength{\tabcolsep}{-5pt}
   \begin{tabular}{|cl|c|c|c|c|c|c|c|}
        \hline \hline
            {\tiny 4a. Execução }   &   & \multicolumn{7}{c|}{Atributos}                                               \\ \cline{3-9} 
       \multicolumn{1}{|l}{}                            &   & A    & B & C & D & E & F & G \\ \hline
        \multicolumn{1}{|c|}{}                           & 1 & 91.4 & 88.5   & 54.2      & 75.7 & 85.7 & 62.8   & 61.4   \\ \cline{2-9} 
        \multicolumn{1}{|c|}{}                           & 2 & 95.7 & 90.0   & 50.0      & 92.8 & 90.0 & 38.5  & 85.7  \\ \cline{2-9} 
        \multicolumn{1}{|c|}{\multirow{-3}{*}{Clusters}} & 3 & 91.4 & 95.7   & 72.8      & 85.7 & 94.2 & 64.2  & 57.1  \\ \hline
   \end{tabular}
   \\
 
 \end{tabular}
 \label{tab:execucoes:seed:nb}
\end{table}

Para provar empiricamente os resultados, na tabela \ref{tab:execucoes:seed:nb} é exposto o resultado de ${4(quatro)}$ execuções do Algoritmo Naive Bayes, e pode-se constatar que mesmo havendo algumas alterações em seus valores nos atributos em cada execução, a correlação entre os atributos não oferece muita alteração. Como exemplo, o atributo \textbf{area} nos clusters 1 e 2, possuem o melhor grau de correlacionamento em seus grupos, mesmo nas quatro execuções, como mostrado na tabela \ref{tab:execucoes:seed:nb}.

Segue abaixo o resultado do algoritmo Naive Bayes na base de dados \textbf{Seeds} com seus rótulos: 
\begin{itemize}[noitemsep]
 \item ${r_{c_1}=\{ (area, ]12.78 \sim 16.14]) \} }$  
 \item ${r_{c_2}=\{ (area, ]16.14 \sim 21.18]) \} }$
 \item ${r_{c_3}=\{ (perimetro, [12.41 \sim 13.73])\} }$
\end{itemize}


\subsection{CART}\label{cap:resultados:ssec:seed:cart}


Já na tabela \ref{tab:rot:seeds:cart}, tem-se o resultado da aplicação do algoritmo supervisionado na rotulação. Ele é um algoritmo de classificação de árvore de decisão utilizado pela toolbox do MATLAB. O intuito é testar a base de dados em diferentes paradigmas.

\begin{table}[!h]
\centering
\caption{Resultado da aplicação do algoritmo CART}
\label{tab:rot:seeds:cart}
\begin{tabular}{llcrc}\hline

\multicolumn{1}{c}{\cellcolor[HTML]{FFFFFF}} & \multicolumn{2}{c}{Rótulos}                      & \multicolumn{1}{r}{}            \\ \cline{2-3}
Cluster                                      & Atributos      & \multicolumn{1}{c}{Faixa}       & \multicolumn{1}{c}{Relevância(\%)} & Elem fora da Faixa \\ \hline \hline
%                                             & area           & ] 12.78 $\sim$  16.14 ]         & 91\%          & 14 \\  
1                                            & perimetro      & [ 13.73 $\sim$ 15.18 ]          & 94\%          & 14\\ \hline
                                             & area           & ] 16.14 $\sim$  21.18 ]          & 98\%         & 6 \\ 
\multirow{-2}{*}{2}                          & perimetro      & ] 15.18 $\sim$  17.25 ]          & 98\%         & 7\\  \hline
%                                             & perimetro      & [ 12.41 $\sim$  13.73 ]         & 95\%          & 5 \\
3                                            & wkernel        & [ 2.63 $\sim$  3.049 ]         & 97\%           & 9\\ \hline \hline
\end{tabular}
\end{table}


Foram realizadas vários teste, onde alguns desses testes estão na tabela \ref{tab:execucoes:seed:cart}. Essas operações foram execuções do algoritmo CART na base, para provar que a técnica de correlação de atributos, seção \ref{cap:ferramentas:sec:tecnica}, é funcional para este algoritmo. O mesmo comportamento entre execuções pode ser visto no algoritmo de paradigma estatístico, subseção \ref{cap:resultados:ssec:seed:nb}, realizado nessa pesquisa. O  comportamento de ambos foram bem semelhantes, como tambéms seus valores não se alteram muito a cada iteração.


\begin{table}[!h]
    
    \caption{Resultado da Correlação dos atributos pelo CART; Legenda dos Atributos: (A)area, (B)perimetro, (C)compacteness, (D)Lkernel, (E)Wkernel, (F)asymetry, (G)lkgroove}    
    \centering
   \small\addtolength{\tabcolsep}{1pt}
    \begin{tabular}{|cl|c|c|c|c|c|c|c|}
        \hline \hline
                                &   & \multicolumn{7}{c|}{Atributos}          \\ \cline{3-9} 
        \multicolumn{1}{|l}{}                            &   & A    & B & C & D & E & F & G \\ \hline
        \multicolumn{1}{|c|}{}                           & 1 & 91.4 & 94.2   & 58.5      & 80.0 & 81.4 & 61.4   & 61.4   \\ \cline{2-9} 
        \multicolumn{1}{|c|}{}                           & 2 & 98.5 & 98.5   & 51.4      & 90.0 & 88.5 & 42.8  & 88.5  \\ \cline{2-9} 
        \multicolumn{1}{|c|}{\multirow{-3}{*}{Clusters}} & 3 & 92.7 & 95.7   & 80.0      & 88.5 & 97.1 & 58.5  & 78.5  \\ \hline
    \end{tabular}
    \label{tab:matrelevancia:seeds:cart} 
\end{table}

\begin{table}[!h]
\caption{Resultado de ${4(quatro)}$ iterações do algoritmo CART; Legenda dos Atributos: (A)area, (B)perimetro, (C)compacteness, (D)Lkernel, (E)Wkernel, (F)asymetry, (G)lkgroove}
 \begin{tabular}{ll}
%\rule{0}{50}

  
   %\scalebox{0.5}{%
   \small\addtolength{\tabcolsep}{-5pt}
     \begin{tabular}{|cl|c|c|c|c|c|c|c|}
        \hline \hline
           {\tiny  1a. Execução}      &   & \multicolumn{7}{c|}{Atributos}                                               \\ \cline{3-9} 
       \multicolumn{1}{|l}{}                            &   & A    & B & C & D & E & F & G \\ \hline
        \multicolumn{1}{|c|}{}                           & 1 & 91.4 & 94.2   & 58.5      & 80.0 & 74.2 & 55.7   & 60.0   \\ \cline{2-9} 
        \multicolumn{1}{|c|}{}                           & 2 & 98.5 & 98.5   & 50.0      & 90.0 & 88.5 & 41.4  & 90.0  \\ \cline{2-9} 
        \multicolumn{1}{|c|}{\multirow{-3}{*}{Clusters}} & 3 & 92.8 & 95.7   & 80.0      & 88.5 & 97.1 & 55.7  & 77.1  \\ \hline
      \end{tabular}
    %}
 &
 %\hspace{1cm} %altera o espaçamento entre as tabelas
 
   
 %\scalebox{0.5}{%
   \small\addtolength{\tabcolsep}{-5pt}
   \begin{tabular}{|cl|c|c|c|c|c|c|c|}
        \hline \hline
         {\tiny  2a. Execução} &   & \multicolumn{7}{c|}{Atributos}                                               \\ \cline{3-9} 
       \multicolumn{1}{|l}{}                            &   & A    & B & C & D & E & F & G \\ \hline
        \multicolumn{1}{|c|}{}                           & 1 &  91.4 & 94.2   & 62.8      & 78.5 & 81.4 & 61.4   & 57.1   \\ \cline{2-9} 
        \multicolumn{1}{|c|}{}                           & 2 & 98.5 & 98.5   & 54.2      & 90.0 & 88.5 & 40.0  & 90.0  \\ \cline{2-9} 
        \multicolumn{1}{|c|}{\multirow{-3}{*}{Clusters}} & 3 & 92.8 & 95.7   & 80.0      & 88.5 & 97.1 & 60.0  & 77.1  \\ \hline
      \end{tabular}
  %}
  \\  [8ex]
 %\hspace{1cm} %altera o espaçamento entre as tabelas
 %\rule{0}{50}
 
 %\scalebox{0.5}{%
   \small\addtolength{\tabcolsep}{-5pt}
   \begin{tabular}{|cl|c|c|c|c|c|c|c|}
        \hline \hline
          {\tiny  3a. Execução}   &   & \multicolumn{7}{c|}{Atributos}                                               \\ \cline{3-9} 
       \multicolumn{1}{|l}{}                            &   & A    & B & C & D & E & F & G \\ \hline
        \multicolumn{1}{|c|}{}                           & 1 & 93.8 & 93.6   & 61.8      & 83.2 & 89.2 & 53.2   & 71.0   \\ \cline{2-9} 
        \multicolumn{1}{|c|}{}                           & 2 & 98.2 & 98.3   & 61.9      & 93.0 & 90.5 & 25.2  & 90.1  \\ \cline{2-9} 
        \multicolumn{1}{|c|}{\multirow{-3}{*}{Clusters}} & 3 & 95.5 & 96.3   & 82.4      & 90.9 & 97.7 & 59.3  & 77.0  \\ \hline
   \end{tabular}
    
    &
    
       \small\addtolength{\tabcolsep}{-5pt}
   \begin{tabular}{|cl|c|c|c|c|c|c|c|}
        \hline \hline
         {\tiny 4a. Execução}       &   & \multicolumn{7}{c|}{Atributos}                                               \\ \cline{3-9} 
       \multicolumn{1}{|l}{}                            &   & A    & B & C & D & E & F & G \\ \hline
        \multicolumn{1}{|c|}{}                           & 1 & 92.8 & 94.2   & 60.0      & 80.0 & 84.2 & 64.2   & 60.0   \\ \cline{2-9} 
        \multicolumn{1}{|c|}{}                           & 2 & 98.5 & 98.5   & 47.1      & 91.4 & 90.0 & 42.8  & 88.5  \\ \cline{2-9} 
        \multicolumn{1}{|c|}{\multirow{-3}{*}{Clusters}} & 3 & 91.4 & 95.7   & 80.0      & 88.5 & 97.1 & 55.7  & 77.1  \\ \hline
   \end{tabular}
   \\
 
 \end{tabular}
 \label{tab:execucoes:seed:cart}
\end{table}

O resultado da rotulaçao utilizando o algoritmo CART na base de dados \textbf{Seeds} tem como rótulos: 
\begin{itemize}[noitemsep]
 \item ${r_{c_1}=\{ (perimetro, ]13.73 \sim 15.18]) \} }$
 \item ${r_{c_2}=\{ (area, ]16.14 \sim 21.18]), (perimetro, ]15.18 \sim 17.25]) \} }$
 \item ${r_{c_3}=\{ (wkernet, [2.63 \sim 3.049]) \} }$
\end{itemize}


\section{Iris - Identificação de Tipos de Plantas}


A base de dados \textbf{Iris}, também pertencente a UCI Machine Learning, é muito conhecida em outras pesquisas\footnote{\cite{LOPES2014,kotsiantis2005logitboost,Filho2015} e outros} como também na literatura em reconhecimentos de padrões por utilizar classes de plantas bem definidas. Contêm 3 classes de 50 instâncias cada, totalizando  150 registros de amostra de plantas. O atributo classe classifica o tipo de planta em 3 tipos:

\begin{itemize}[noitemsep]
 \item 50 elementos da classe Iris-setosa ;
 \item 50 elementos da classe Iris-versicolour;
 \item 50 elementos da classe Iris-virginica.
\end{itemize}

Os atributos correspondentes são comprimento da sepala - SL, largura da sepala - SW, comprimento da pétala - PL e
largura da pétala - PW. Através dessas características há uma classificação para dizer qual tipo de planta.

Foi aplicado na configuração de execução do algoritmo o método de discretização, tipo EFD\footnote{seção \ref{cap:refTeor:subsec:efd}}, a divisão de três faixas de valores R = 3 para todos os atributos, e inserido o valor de variação ${V=0\%}$. Mais uma vez, o valor ${V}$ existe para evitar ambiguidade dos rótulos, podendo ser utilizado pelo pesquisador quando necessário após análise dos valores de correlação dos atributos nos grupos, tabela \ref{tab:execucoes:iris:nb}.

Seguindo a análise, semelhante da base de dados anterior, serão realizados testes utilizando dois algoritmos\footnote{sessões \ref{cap:resultados:ssec:seed:nb},\ref{cap:resultados:ssec:seed:cart}}, e cada resultado será exibido em tabelas. Portando as colunas são formadas por \textbf{Clusters}, \textbf{Rótulos}, \textbf{Relevância} e \textbf{Elem fora da Faixa} representando os valores que não estão dentro da faixa escolhida como rótulo. Também foi posto nas tabelas \ref{tab:execucoes:iris:cart} e \ref{tab:execucoes:iris:nb} os resultados das correlações entre os atributos de cada grupo, servindo de informação para decisão do valor de ${V}$, caso fosse necessário. E também apresentado os resultados de outras iterações de cada algoritmo, para mostrar o comportamento dos atributos entre eles no grupo.

\subsection{Naive Bayes} \label{cap:resultados:ssec:iris:nb}

Através da tabela \ref{tab:rot:iris:nb} os resultados da rotulação são exibidos após a aplicação do algoritmo. Com essa base de dados nota-se que no cluster 1 houve um acerto de 100\% da rotulação. O cluster 2 e cluster 3 obtiveram rótulos distintos, cada um com com grau de relevância acima de 80\% em relação aos outros atributos de cada grupo.

\begin{table}[!h]
\centering
\caption{Resultado da aplicação do algoritmo Naive Bayes}
\label{tab:rot:iris:nb}
\begin{tabular}{llcrc} \hline
 
\multicolumn{1}{c}{\cellcolor[HTML]{FFFFFF}} & \multicolumn{2}{c}{Rótulos}                & \multicolumn{1}{r}{}               & \\ \cline{2-3}
Cluster                                      & Atributos      & \multicolumn{1}{c}{Faixa} & \multicolumn{1}{c}{Relevância(\%)} & Elem fora da Faixa\\ \hline \hline
                                             & petallength    & [ 1.0 $\sim$  3.7 ]       & 100\%                               & 0 \\  
\multirow{-2}{*}{1}                          & petalwidth     & [ 0.1 $\sim$  1.0 ]       & 100\%                               & 0 \\  \hline
2                                             & petallength    & ] 3.7 $\sim$  5.1 ]       & 84\%                               & 7\\ \hline
%\multirow{-2}{*}{2}                          & petalwidth     & ] 1.0 $\sim$  1.7 ]       & 82\%                               & 8\\  \hline
3                                            & petalwidth     & ] 1.7 $\sim$  2.5 ]       & 90\%                               & 5\\ \hline \hline
\end{tabular}
\end{table}

Os valore na coluna de relevância não podem ser analisados isoladamente. Para isso  a tabela \ref{tab:execucoes:iris:nb} possui os valores de todos os atributos no momento que ele são classes. Os valores são em porcentagem para melhor análise do grau de relacionamento entre os outros atributos.

\begin{table}[!h]
\caption{Resultado de ${4(quatro)}$ execuções do algoritmo Naive Bayes; Legenda dos Atributos: (SL)sepallength,(SW)sepalwidth,(PL)petallength,(PW)petalwidth}
 \begin{tabular}{ll}
%\rule{0}{50}

  
   %\scalebox{0.5}{%
   \small\addtolength{\tabcolsep}{-1pt}
     \begin{tabular}{|cl|c|c|c|c|}
        \hline \hline
                  1a. Execução   &   & \multicolumn{4}{c|}{Atributos}                                               \\ \cline{3-6} 
       \multicolumn{1}{|l}{}                             &   & SL   & SW     & PL    & PW      \\ \hline
        \multicolumn{1}{|c|}{}                           & 1 & 80   & 68     & \textbf{100}   & \textbf{100}       \\ \cline{2-6} 
        \multicolumn{1}{|c|}{}                           & 2 & 72 & 76   & \textbf{84}  & \textbf{82}     \\ \cline{2-6} 
        \multicolumn{1}{|c|}{\multirow{-3}{*}{Clusters}} & 3 & 76 & 74   & 68  & \textbf{90}     \\ \hline
      \end{tabular}
    %}
 &
 %\hspace{1cm} %altera o espaçamento entre as tabelas
 
   
 %\scalebox{0.5}{%
  \small\addtolength{\tabcolsep}{-1pt}
     \begin{tabular}{|cl|c|c|c|c|}
        \hline \hline
         2a. Execução         &   & \multicolumn{4}{c|}{Atributos}                                               \\ \cline{3-6} 
       \multicolumn{1}{|l}{}                             &   & SL   & SW     & PL    & PW      \\ \hline
        \multicolumn{1}{|c|}{}                           & 1 & 80 & 68   & 100 &  100      \\ \cline{2-6} 
        \multicolumn{1}{|c|}{}                           & 2 & 72 & 76   & 88  &    84  \\ \cline{2-6} 
        \multicolumn{1}{|c|}{\multirow{-3}{*}{Clusters}} & 3 & 70 & 74   & 70  &  90    \\ \hline
      \end{tabular}
  %}
  \\  [8ex]
 %\hspace{1cm} %altera o espaçamento entre as tabelas
 %\rule{0}{50}
 
 %\scalebox{0.5}{%
   \small\addtolength{\tabcolsep}{-1pt}
     \begin{tabular}{|cl|c|c|c|c|}
        \hline \hline
         3a. Execução           &   & \multicolumn{4}{c|}{Atributos}                                               \\ \cline{3-6} 
       \multicolumn{1}{|l}{}                             &   & SL   & SW     & PL    & PW      \\ \hline
        \multicolumn{1}{|c|}{}                           & 1 & 80 & 68   & 100  & 100       \\ \cline{2-6} 
        \multicolumn{1}{|c|}{}                           & 2 & 72 & 74   & 84  &  84    \\ \cline{2-6} 
        \multicolumn{1}{|c|}{\multirow{-3}{*}{Clusters}} & 3 & 74 & 74   & 68  &   90   \\ \hline
      \end{tabular}
    
    &
    
 \small\addtolength{\tabcolsep}{-1pt}
     \begin{tabular}{|cl|c|c|c|c|}
        \hline \hline
        4a. Execução      &   & \multicolumn{4}{c|}{Atributos}                                               \\ \cline{3-6} 
       \multicolumn{1}{|l}{}                             &   & SL   & SW     & PL    & PW      \\ \hline
        \multicolumn{1}{|c|}{}                           & 1 & 80 & 68   & 100  &   100     \\ \cline{2-6} 
        \multicolumn{1}{|c|}{}                           & 2 & 72 & 74   & 86  &   82   \\ \cline{2-6} 
        \multicolumn{1}{|c|}{\multirow{-3}{*}{Clusters}} & 3 & 70 & 74   & 70  & 92     \\ \hline
      \end{tabular}
   \\
 
 \end{tabular}
 \label{tab:execucoes:iris:nb}
\end{table}

Na tabela \ref{tab:execucoes:iris:nb} foram inseridas quatro resultados de execuções do algoritmo. Foi escolhida na tabela \ref{tab:execucoes:iris:nb} a 1a. execução para montar a tabela de rótulos, tabela \ref{tab:rot:iris:nb}. A partir dessas execuções o pesquisador poderá arbitrá sobre o valor de ${V}$ para melhor adaptá-lo a base. Das várias execuções expostas na tabela \ref{tab:execucoes:iris:nb}, percebe-se que não há muita diferença entre os valores de cada execução. Isso mostra um padrão de valores de acordo com a base. No caso da 1a. execução os valores escolhidos como rótulo estão destacados em cada cluster.

Se a tabela escolhida fosse a da 3a. execução, os valores de rótulos seriam modificados, em virtude dos valores mais altos serem iguais, fazendo que o rótulo assumisse dois atributos: PL e PW. Em análise do cluster 2 perecebe-se que os valores de PL e PW nas quatro execuções são bem próximos e até idênticos na terceira execução, como já dito anteriormente, então caso fosse necessário inserir um valor de variação ${V}$, um valor aceitável seria ${V=3}$. Desta maneira manteria os rótulos dos clusters 1 e 3 sem alteração, e um novo atributo seria incluído no cluster 2, assumindo o novo rótulo com dois atributos: PL e PW.

Os rótulos com o algoritmo Naive Bayes na base de dados \textbf{Iris} são dados abaixo:
\begin{itemize}[noitemsep]
 \item ${r_{c_1}=\{ (petallength, [ 1.0 \sim 3.7]), (petalwidth,[ 0.1 \sim 1.0 ] ) \} }$  
 \item ${r_{c_2}=\{ (petallength, ] 3.7 \sim 5.1]) \} }$
 \item ${r_{c_3}=\{ (petalwidth, ] 1.7 \sim 2.5 ]) \} }$
\end{itemize}

\subsection{CART} \label{cap:resultados:ssec:iris:cart}

A aplicação do algoritmo CART na base de dados \textbf{Iris} gerou a tabela \ref{tab:rot:iris:cart} como resultado, e ao examinar pode-se observar uma semelhança com a subseção anterior \ref{cap:resultados:ssec:iris:nb} onde foi aplicado o Naive Bayes. 

\begin{table}[!h]
\centering
\caption{Resultado da aplicação do algoritmo CART}
\label{tab:rot:iris:cart}
\begin{tabular}{llcrc} \hline
 
\multicolumn{1}{c}{\cellcolor[HTML]{FFFFFF}} & \multicolumn{2}{c}{Rótulos}                & \multicolumn{1}{r}{}               & \\ \cline{2-3}
Cluster                                      & Atributos      & \multicolumn{1}{c}{Faixa} & \multicolumn{1}{c}{Relevância(\%)} & Elem fora da Faixa\\ \hline \hline
                                             & petallength    & [ 1.0 $\sim$  3.7 ]       & 100\%                               & 0 \\  
\multirow{-2}{*}{1}                          & petalwidth     & [ 0.1 $\sim$  1.0 ]       & 100\%                               & 0 \\  \hline
%                                             & petallength    & ] 3.7 $\sim$  5.1 ]       & 88\%                               & 7\\ 
2                                            & petalwidth     & ] 1.0 $\sim$  1.7 ]       & 90\%                               & 8\\  \hline
3                                            & petalwidth     & ] 1.7 $\sim$  2.5 ]       & 90\%                               & 5\\ \hline \hline
\end{tabular}
\end{table}

Ao observar a tabela \ref{tab:rot:iris:cart} percebe-se que o resultado de rotulação no cluster 1 e 3 são idênticos ao do algoritmo apresentado anteriormente, mas  no cluster 2 o rótulo é diferenciado pelo atributo petalwidth que atinge valores mais altos em todas as execuções, como mostra a tabela \ref{tab:execucoes:iris:nb}.



\begin{table}[!h]
\caption{Resultado de ${4(quatro)}$ iterações do algoritmo CART; Legenda dos Atributos: (SL)sepallength,(SW)sepalwidth,(PL)petallength,(PW)petalwidth}
 \begin{tabular}{ll}
%\rule{0}{50}

  
   %\scalebox{0.5}{%
   \small\addtolength{\tabcolsep}{-1pt}
     \begin{tabular}{|cl|c|c|c|c|}
        \hline \hline
                  1a. Execução   &   & \multicolumn{4}{c|}{Atributos}                                               \\ \cline{3-6} 
       \multicolumn{1}{|l}{}                             &   & SL   & SW     & PL    & PW      \\ \hline
        \multicolumn{1}{|c|}{}                           & 1 & 80   & 68     & \textbf{100}   & \textbf{100}       \\ \cline{2-6} 
        \multicolumn{1}{|c|}{}                           & 2 & 74 & 76   & \textbf{88}  & \textbf{90}     \\ \cline{2-6} 
        \multicolumn{1}{|c|}{\multirow{-3}{*}{Clusters}} & 3 & 68 & 68   & 74  & \textbf{90}     \\ \hline
      \end{tabular}
    %}
 &
 %\hspace{1cm} %altera o espaçamento entre as tabelas
 
   
 %\scalebox{0.5}{%
  \small\addtolength{\tabcolsep}{-1pt}
     \begin{tabular}{|cl|c|c|c|c|}
        \hline \hline
         2a. Execução         &   & \multicolumn{4}{c|}{Atributos}                                               \\ \cline{3-6} 
       \multicolumn{1}{|l}{}                             &   & SL   & SW     & PL    & PW      \\ \hline
        \multicolumn{1}{|c|}{}                           & 1 & 80 & 68   & 100 &  100      \\ \cline{2-6} 
        \multicolumn{1}{|c|}{}                           & 2 & 74 & 76   & 88  &    90  \\ \cline{2-6} 
        \multicolumn{1}{|c|}{\multirow{-3}{*}{Clusters}} & 3 & 70 & 70   & 74  &  90    \\ \hline
      \end{tabular}
  %}
  \\  [8ex]
 %\hspace{1cm} %altera o espaçamento entre as tabelas
 %\rule{0}{50}
 
 %\scalebox{0.5}{%
   \small\addtolength{\tabcolsep}{-1pt}
     \begin{tabular}{|cl|c|c|c|c|}
        \hline \hline
         3a. Execução           &   & \multicolumn{4}{c|}{Atributos}                                               \\ \cline{3-6} 
       \multicolumn{1}{|l}{}                             &   & SL   & SW     & PL    & PW      \\ \hline
        \multicolumn{1}{|c|}{}                           & 1 & 80 & 68   & 100  & 100       \\ \cline{2-6} 
        \multicolumn{1}{|c|}{}                           & 2 & 74 & 76   & 86  &  90    \\ \cline{2-6} 
        \multicolumn{1}{|c|}{\multirow{-3}{*}{Clusters}} & 3 & 70 & 66   & 78  &   90   \\ \hline
      \end{tabular}
    
    &
    
 \small\addtolength{\tabcolsep}{-1pt}
     \begin{tabular}{|cl|c|c|c|c|}
        \hline \hline
        4a. Execução      &   & \multicolumn{4}{c|}{Atributos}                                               \\ \cline{3-6} 
       \multicolumn{1}{|l}{}                             &   & SL   & SW     & PL    & PW      \\ \hline
        \multicolumn{1}{|c|}{}                           & 1 & 80 & 68   & 100  &   100     \\ \cline{2-6} 
        \multicolumn{1}{|c|}{}                           & 2 & 72 & 74   & 86  &   90   \\ \cline{2-6} 
        \multicolumn{1}{|c|}{\multirow{-3}{*}{Clusters}} & 3 & 68 & 66   & 78  & 90     \\ \hline
      \end{tabular}
   \\
 
 \end{tabular}
 \label{tab:execucoes:iris:cart}
\end{table}


Segue abaixo os rótulos na base de dados \textbf{Iris} aplicado no algoritmo CART:
\begin{itemize}[noitemsep]
 \item ${r_{c_1}=\{ (petallength, [ 1.0 \sim 3.7]), (petalwidth,[ 0.1 \sim 1.0 ] ) \} }$  
 \item ${r_{c_2}=\{ (petallength, ] 3.7 \sim 5.1]), (petalwidth,] 1.0 \sim 1.7 ] )\} }$
 \item ${r_{c_3}=\{ (petalwidth, ] 1.7 \sim 2.5 ]) \} }$
\end{itemize}


\section{Glass - Identificação de Tipos de Vidros}\label{cap:resultados:ssec:iris}

Essa base ficou conhecida por Vina Spiehler, Ph.D. da DABFT Diagnostic Products Corporation, onde conduzio pesquisas e teste de comparação em seu sistema baseado em regras determinando, se o tipo de vidro era temperado ou não. Institutos de investigação criminológica motivaram os estudos de classificação de tipos de vidros, porque uma classificação corretamente identificada em uma cena de crime pode ser utilizada como prova.

Possui um total de 214 instancias, caracterizados por 9 atributos (RI, Na, Mg, Al, Si, K, Ca, Ba e Fe), sendo que o atributo \textbf{RI} indica o índice de refração, e quanto aos demais atributos são valores correspondentes a porcentagem do óxido.

Os tipos de vidro (atributo classe) foram divididos em 7 grupos distintos:
\begin{itemize}
 \item 1 janelas de construção - vidro temperado: 70 registros
 \item 2 janelas de construção - vidro não-temperado: 76 registros
 \item 3 janelas de veículos - vidro temperado: 17 registros
 \item 4 janelas de veículos - vidro não-temperado: 0 registro
 \item 5 recipientes: 13 registros
 \item 6 louças de mesa: 9 registros
 \item 7 lâmpadas: 29 registros
\end{itemize}

Para execução dos algoritmos terão que ser definidos em quantas em quantas faixas (${R}$) serão divididos os valores dos atributos, qual é o método de discretização e o valor de variação ${V}$ caso haja ambiguidade. Nos teste desenvolvidos nesta pesquisa os valore de referência foram, ${R=0}$, o método de discretização EFD e o valor de ${=0}$.


\subsection{Naive Bayes} \label{cap:resultados:ssec:glass:nb}



\begin{table}[!h]
\centering
\caption{Resultado da aplicação do algoritmo CART}
\label{tab:rot:iris:cart}
\begin{tabular}{llcrc} \hline
 
\multicolumn{1}{c}{\cellcolor[HTML]{FFFFFF}} & \multicolumn{2}{c}{Rótulos}                & \multicolumn{1}{r}{}               & \\ \cline{2-3}
Cluster                                      & Atributos      & \multicolumn{1}{c}{Faixa} & \multicolumn{1}{c}{Relevância(\%)} & Elem fora da Faixa\\ \hline \hline
                                             & Mg    & [ 2.245 $\sim$  4.490     ]       & 100\%                               & 0 \\
                                             & K     & [ 0.0 $\sim$  1.5525      ]       & 100\%                               & 0 \\  
\multirow{-3}{*}{1}                          & Ba    & [ 0.0 $\sim$  0.7875     ]       & 100\%                               & 0 \\  \hline
%                                             & petallength    & ] 3.7 $\sim$  5.1 ]       & 88\%                               & 7\\ 
2                                            & K     & ] 0.0 $\sim$  1.5525 ]           & 100\%                               & 0\\  \hline
                                            & Mg     & ]  2.245 $\sim$  4.490  ]              & 100\%                               & 0\\ 
                                            & K     & ] 0.0 $\sim$  1.5525 ]               & 100\%                               & 0\\  
                                            & Ca     & ] 8.12 $\sim$  10.81 ]       & 100\%                               & 0\\ 
\multirow{-3}{*}{3}                          & Ba    & [ 0.0 $\sim$  0.7875     ]       & 100\%                               & 0 \\  \hline
                                             & Al    & [ 1.0925 $\sim$  1.895 ]       & 92\%                               & 4 \\
                                             & K     & [ 0.0 $\sim$  1.5525      ]       & 92\%                               & 3 \\  
\multirow{-3}{*}{4}                          & Ba    & [ 0.0 $\sim$  0.7875     ]       & 92\%                               & 1 \\  \hline
                                            & Na    & [14.055 $\sim$ 17.38  ]           & 100\%                             & 2 \\
                                            & K     & [ 0.0 $\sim$  1.5525      ]       & 100\%                               & 0 \\  
                                            & Ba    & [ 0.0 $\sim$  0.7875     ]       & 100\%                               & 0 \\   
\multirow{-4}{*}{5}                          & Fe    & [ 0.0 $\sim$  0.1275     ]       & 100\%                               & 0 \\  \hline
\hline

\end{tabular}
\end{table}






\subsection{Naive Bayes} \label{cap:resultados:ssec:glass:cart}
