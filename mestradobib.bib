Automatically generated by Mendeley Desktop 1.17.12
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Trandafili2012,
abstract = {Higher education institutions are overwhelmed with huge amounts of information regarding student's enrollment, number of courses completed, achievement in each course, performance indicators and other data. This has led to an increasingly complex analysis process of the growing volume of data and to the incapability to take decisions regarding curricula reform and restructuring. On the other side, educational data mining is a growing field aiming at discovering knowledge from student's data in order to thoroughly understand the learning process and take appropriate actions to improve the student's performance and the quality of the courses delivery. This paper presents a thorough analysis process performed on student's data through machine learning techniques. Experiments performed on a very large real-world dataset of students performance on all courses of a university, reveal interesting and important students profiles with clustering and surprising relationships among the courses performance with association},
author = {Trandafili, Evis and Allko{\c{c}}i, Alban and Kajo, Elinda and Xhuvani, Aleksand{\"{e}}r},
doi = {10.1145/2371316.2371350},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/p174-trandafili.pdf:pdf},
isbn = {9781450312400},
journal = {Proceedings of the Fifth Balkan Conference in Informatics on - BCI '12},
pages = {174},
title = {{Discovery and evaluation of student's profiles with machine learning}},
url = {http://dl.acm.org/citation.cfm?doid=2371316.2371350},
year = {2012}
}
@article{Chang2016,
author = {Chang, Shuo and Dai, Peng and Hong, Lichan and Sheng, Cheng and Zhang, Tianjiao and Chi, Ed H.},
doi = {10.1145/2856767.2856783},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/p348-chang.pdf:pdf},
isbn = {9781450341370},
journal = {Proceedings of the 21st International Conference on Intelligent User Interfaces - IUI '16},
keywords = {clustering,interactive machine learning,search result clustering},
pages = {348--358},
title = {{AppGrouper: Knowledge-graph-based Interactive Clustering Tool for Mobile App Search Results}},
url = {http://dl.acm.org/citation.cfm?doid=2856767.2856783},
year = {2016}
}
@article{Yang2011,
abstract = {Previous semi-supervised learning (SSL) techniques usually assume unlabeled data are relevant to the target task. That is, they follow the same distribution as the targeted labeled data. In this paper, we address a different and very difficult scenario in SSL, where the unlabeled data may be a mixture of data relevant or irrelevant to the target binary classification task. In our framework, we do not require explicitly prior knowledge on the relatedness of the unla- beled data to the target data. In order to alleviate the effect of the irrelevant unlabeled data and utilize the implicit knowledge among all available data, we develop a novel maximum margin classifier, named the tri-class support vector machine (3C-SVM), to seek an inductive rule to separate the target binary classification task well while finding out the irrelevant data by-product. To attain this goal, we introduce a new min loss function, which can relieve the impact of the irrelevant data while relying more on the labeled data and the relevant unlabeled data. This loss function can therefore achieve the maximum entropy principle. The 3C-SVM can then generalize standard SVMs, Semi-supervised SVMs, and SVMs learned from the universum as its special cases. We further analyze the proper- ty of 3C-SVM on why the irrelevant data can help to improve the model performance. For implementation, we make relaxation and approximate the objective by the convex-concave procedure, which turns the original optimization from integral programming problem to a problem by just solving a finite number of quadratic program- ming problems. Empirical results are reported to demonstrate the advantages of our 3C-SVM model.},
author = {Yang, Haiqin and Zhu, Shenghuo and King, Irwin and Lyu, Michael R.},
doi = {10.1145/2063576.2063711},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/p937-yang.pdf:pdf},
isbn = {9781450307178},
journal = {Proceedings of the 20th ACM international conference on Information and knowledge management - CIKM '11},
keywords = {att,com,irwin,previous semi-supervised learning,research,ssl,techniques usually assume,that is,they follow,to the target task,unlabeled data are relevant},
pages = {937},
title = {{Can irrelevant data help semi-supervised learning, why and how?}},
url = {http://dl.acm.org/citation.cfm?doid=2063576.2063711},
year = {2011}
}
@article{Morasca2002,
abstract = {Classification trees have been successfully used in several application fields. However, continuous attributes cannot be used directly when building classification trees, but they must be first discretized with clustering techniques, which require some degree of subjectivity. We propose an approach to build classification trees that does not require the discretization of the continuous attributes. The approach is an extension of existing methods for building classification trees and is based on the information gain yielded by discrete and continuous attributes. Data from a software development case study are analyzed with both the proposed approach and C4.5 to show the approach's applicability and benefits over C4.5. Copyright 2002 ACM.},
author = {Morasca, Sandro and Chimiche, Scienze and Matematiche, Fisiche},
doi = {10.1145/568760.568832},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/p417-morasca.pdf:pdf},
isbn = {1581135564},
keywords = {5,c4,continuous attributes,decision trees,id3},
pages = {0--7},
title = {{A Proposal for Using Continuous Attributes in Classification Trees}},
year = {2002}
}
@article{Steiner2006,
abstract = {A “Descoberta de Conhecimento em Bases de Dados” (Knowledge Discovery in Databases, KDD) {\'{e}} um processo composto de v{\'{a}}rias etapas, iniciando com a coleta de dados para o problema em pauta e finalizando com a interpreta- {\c{c}}{\~{a}}o e avalia{\c{c}}{\~{a}}o dos resultados obtidos. O presente trabalho objetiva mostrar a influ{\^{e}}ncia da an{\'{a}}lise explorat{\'{o}}ria dos dados no desempenho das t{\'{e}}cnicas de Minera{\c{c}}{\~{a}}o de Dados (Data Mining) quanto {\`{a}} classifica{\c{c}}{\~{a}}o de novos padr{\~{o}}es por meio da sua aplica{\c{c}}{\~{a}}o a um problema m{\'{e}}dico, al{\'{e}}m de comparar o desempenho delas entre si, visando obter a t{\'{e}}cnica com o maior percentual de acertos. Pelos resultados obtidos, pode-se concluir que a referida an{\'{a}}lise, se conduzida de forma adequada, pode trazer importantes melhorias nos desempenhos de quase todas as t{\'{e}}cnicas abor- dadas, tornando-se, assim, uma importante ferramenta para a otimiza{\c{c}}{\~{a}}o dos resultados finais. Para o problema em estudo, a t{\'{e}}cnica que envolve um modelo de Programa{\c{c}}{\~{a}}o Linear e uma outra que envolve Redes Neurais foram as t{\'{e}}cnicas que apresentaram os menores percentuais de erros para os conjuntos de testes, apresentando capacidades de generaliza{\c{c}}{\~{a}}o satisfat{\'{o}}rias.},
author = {Steiner, Maria Teresinha Arns MTA and Soma, Nei Yoshihiro NY and Shimizu, Tamio and Nievola, J{\'{u}}lio Cesar and steiner Neto, Pedro Jos{\'{e}}},
doi = {10.1590/S0104-530X2006000200013},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/31177{\_}problema{\_}medico{\_}processo{\_}kdd{\_}analise{\_}exploratoria{\_}dados.pdf:pdf},
issn = {0104-530X},
journal = {Gest{\~{a}}o {\&} Produ{\c{c}}{\~{a}}o},
keywords = {an{\'{a}}lise explorat{\'{o}}ria dos dados.,minera{\c{c}}{\~{a}}o de dados,processo KDD},
pages = {325--337},
title = {{Abordagem de um problema m{\'{e}}dico por meio do processo de KDD com {\^{e}}nfase {\`{a}} an{\'{a}}lise explorat{\'{o}}ria dos dados.}},
url = {http://www.scielo.br/scielo.php?script=sci{\_}arttext{\&}pid=S0104-530X2006000200013{\&}nrm=iso{\%}5Cnhttp://www.scielo.br/pdf/gp/v13n2/31177.pdf},
volume = {13},
year = {2006}
}
@book{Barber2011,
abstract = {Machine learning methods extract value from vast data sets quickly and with modest resources. They are established tools in a wide range of industrial applications, including search engines, DNA sequencing, stock market analysis, and robot locomotion, and their use is spreading rapidly. People who know the methods have their choice of rewarding jobs. This hands-on text opens these opportunities to computer science students with modest mathematical backgrounds. It is designed for final-year undergraduates and master's students with limited background in linear algebra and calculus. Comprehensive and coherent, it develops everything from basic reasoning to advanced techniques within the framework of graphical models. Students learn more than a menu of techniques, they develop analytical and problem-solving skills that equip them for the real world. Numerous examples and exercises, both computer based and theoretical, are included in every chapter. Resources for students and instructors, including a MATLAB toolbox, are available online.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Barber, David},
doi = {10.1017/CBO9780511804779},
eprint = {arXiv:1011.1669v3},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/Bayesian{\_}reasoning{\_}and{\_}Machine{\_}learning{\_}DAVID{\_}BARBER.pdf:pdf},
isbn = {9780511804779},
issn = {9780521518147},
pmid = {16931139},
title = {{Bayesian Reasoning and Machine Learning}},
url = {http://ebooks.cambridge.org/ref/id/CBO9780511804779},
year = {2011}
}
@book{Wu2008,
abstract = {This paper presents the top 10 data mining algorithms identified by the IEEE International Conference on Data Mining (ICDM) in December 2006: C4.5, k-Means, SVM, Apriori, EM, PageRank, AdaBoost, k NN, Naive Bayes, and CART. These top 10 algorithms are among the most influential data mining algorithms in the research community. With each algorithm, we provide a description of the algorithm, discuss the impact of the algorithm, and review current and further research on the algorithm. These 10 algorithms cover classification, clustering, statistical learning, association analysis, and link mining, which are all among the most important topics in data mining research and development. {\textcopyright} Springer-Verlag London Limited 2007. },
author = {Wu, Xindong and Kumar, Vipin and Ross, Quinlan J. and Ghosh, Joydeep and Yang, Qiang and Motoda, Hiroshi and McLachlan, Geoffrey J. and Ng, Angus and Liu, Bing and Yu, Philip S. and Zhou, Zhi Hua and Steinbach, Michael and Hand, David J. and Steinberg, Dan},
booktitle = {Knowledge and Information Systems},
doi = {10.1007/s10115-007-0114-2},
file = {:home/tarcisio/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/10Algorithms-08.pdf:pdf},
isbn = {1011500701},
issn = {02191377},
number = {1},
pages = {1--37},
pmid = {25720841},
title = {{Top 10 algorithms in data mining}},
volume = {14},
year = {2008}
}
@article{Lorenzett2016,
author = {Lorenzett, Cassio dal Castel and Teloken, Alex},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/4023-10934-1-PB.pdf:pdf},
journal = {Simp{\'{o}}sio de Pesquisa e Desenvolvimento em Computa{\c{c}}{\~{a}}o},
number = {1},
title = {{Estudo Comparativo entre os algoritmos de Minera{\c{c}}{\~{a}}o de Dados Random Forest e J48 na tomada de Decis{\~{a}}o}},
volume = {2},
year = {2016}
}
@article{Monteiro2013,
author = {Monteiro, Felipe},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/c4.5vsMLP-2013 CLAGTEE{\_}submission{\_}141.pdf:pdf},
number = {October},
title = {{aplicados a Avalia{\c{c}}{\~{a}}o da Seguran{\c{c}}a Din{\^{a}}mica e}},
year = {2013}
}
@phdthesis{Madureira2017,
abstract = {Um grande n´ umero de mensagens curtas informais s˜ ao postadas dia- riamente em redes sociais, f´ orums de discuss˜ ao e pesquisas de satisfa¸ao. c˜ Emo¸oes parecem ser importantes de forma frequente nesses textos. O de- c˜ safio de identificar e entender a emo¸ao presente nesse tipo de comunica¸aoc˜ c˜ ´ e importante para distinguir o sentimento presente no texto e tamb´ em para identificar comportamentos anˆ omalos e inapropriados, eventualmente ofere- cendo algum tipo de risco. Este trabalho prop˜ oe a implementa¸ao de uma solu¸ao para a an´ c˜ c˜ alise de sentimento de textos curtos baseada em aprendizado por m´ aquina. Utili- zando t´ ecnicas de aprendizado supervisionado, ´ e desejado discernir se uma mensagem possui sentimento positivo, neutro ou negativo. As mensagens a serem analisadas ser˜ ao pesquisas de satisfa¸ao de servi¸ c˜ cos de TI. Foram uti- lizados nas an´ alises dois modelos, o primeiro modelo onde apenas o campo de texto livre ”Coment´ ario”foi considerado e o segundo modelo, onde al´ em do campo de texto livre ”Coment´ ario”, foram consideradas, adicionalmente, duas perguntas objetivas da pesquisa de satisfa¸ao. c˜ Os resultados obtidos indicam que as t´ ecnicas utilizadas de aprendizado por m´ aquina, n˜ ao ficam atr´ as dos resultados produzidos por aprendizado humano. A acur´ acia obtida foi de at´ e 86,8{\%}de acerto para ummodelo de trˆ es classes: ”elogio”, ”neutro”e ”reclama¸ao”. A acur´ c˜ acia foi significativamente superior, alcan¸ cando at´ e 94,5{\%} em um modelo alternativo, de apenas duas classes: ”elogio”e ”n˜ ao-elogio”},
address = {Rio de Janeiro},
author = {Madureira, Daniel Fialho},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/FGV EMAp - Gustavo Avila - An{\'{a}}lise de Sentimento para Textos Curtos.pdf:pdf},
school = {Fundacao Getulio Vargas},
title = {{Analise de sentimento para textos curtos}},
year = {2017}
}
@article{Sanches2003,
abstract = {In order to apply machine learning classification algorithms, it is assumed that there exists a set of labeled data, called the training set, which is used to train the classifier. However, in real life, this training set may not contain enough labeled data to induce a good classifier. Recently, there has been much interest in a variant of this approach. This new approach, known as semi-supervised learning, assumes that, in addition to the labeled training data, there exists a second set of unlabeled data which is also available during training. One of the goals of semi-supervised learning is training classifiers when large amounts of unlabeled data are available together with a small amount of labeled data. The appeal of semi-supervised learning is due to the fact that in many real-world applications, such sets of unlabeled data are either readily available or inexpensive to collect compared to labeled data. Unlabeled data can often be collected by auto- mated means while labeled data requires human experts or other limited or expensive classification resources that may even be unfeasible in some cases. There are several ways in which unlabeled data can be used. In this work we explore one mechanism by which unlabeled data can be used to improve classification problems and propose a semi-supervised algorithm, called k-meanski, for using unlabeled data for supervised learning. There are two premises underlying the technique used by the proposed algorithm. The first is that input data falls naturally into clusters rather than being uniformly distributed across the entire input space. Furthermore, the initial input labeled data should fall near the center of the existing clusters in the input space. The second premise is that many of the points in some of these clusters belong to specific output categories. Obviously, the validity of these premises is dependent on the dataset used. The k-meanski algorithm works well when the data conform to both premises. If these assumptions are violated poor performance can result. Experiments using real world datasets where we randomly select a subset of the available data to act as labeled exemplars are shown.},
author = {Sanches, Marcelo Kaminski},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/Dissertacao{\_}MKS.pdf:pdf},
title = {{Aprendizado de m{\'{a}}quina semi-supervisionado: proposta de um algoritmo para rotular exemplos a partir de poucos exemplos rotulados}},
year = {2003}
}
@article{Domingos2012,
abstract = {MACHINE LEARNING SYSTEMS automatically learn programs from data. This is often a very attractive alternative to manually constructing them, and in the last decade the use of machine learning has spread rapidly throughout computer science and beyond. Machine learning is used in Web search, spam filters, recommender systems, ad placement, credit scoring, fraud detection, stock trading, drug design, and many other applications. A recent report from the McKinsey Global Institute asserts that machine learning (a.k.a. data mining or predictive analytics) will be the driver of the next big wave of innovation. Several fine textbooks are available to interested practitioners and researchers (for example, Mitchell and Witten et al.). However, much of the “folk knowledge” that is needed to successfully develop machine learning applications is not readily available in them. As a result, many machine learning projects take much longer than necessary or wind up producing less-than-ideal results. Yet much of this folk knowledge is fairly easy to communicate. This is the purpose of this article.},
archivePrefix = {arXiv},
arxivId = {cs/9605103},
author = {Domingos, Pedro},
doi = {10.1145/2347736.2347755},
eprint = {9605103},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/Algumas{\_}informacoes{\_}uteis{\_}sobre{\_}MachineLearning.pdf:pdf},
isbn = {0001-0782},
issn = {00010782},
journal = {Communications of the ACM},
number = {10},
pages = {78},
pmid = {1000183096},
primaryClass = {cs},
title = {{A few useful things to know about machine learning}},
url = {http://dl.acm.org/citation.cfm?doid=2347736.2347755},
volume = {55},
year = {2012}
}
@article{ENS2001,
abstract = {O presente artigo relata a proposta na PUCPR de unir pesquisa e doc{\^{e}}ncia na forma{\c{c}}{\~{a}}o continuada de professores, mais especificamente dos estudos sobre a abordagem qualitativa e a metodologia da pesquisa que est{\'{a}} sendo utilizada no projeto Gest{\~{a}}o Estrat{\'{e}}gica de Compet{\^{e}}ncias e a Forma{\c{c}}{\~{a}}o do Professor. A realiza{\c{c}}{\~{a}}o da pesquisa vem propiciando ao grupo de professores da {\'{a}}rea de educa{\c{c}}{\~{a}}o um trabalho integrado, e ao mesmo tempo, um caminhar pela pes- quisa-a{\c{c}}{\~{a}}o, integrando os seguintes procedimentos e t{\'{e}}cnicas de pesquisa: an{\'{a}}- lise documental, an{\'{a}}lise iconogr{\'{a}}fica, aplica{\c{c}}{\~{a}}o de question{\'{a}}rios, entrevista semi-estruturada, observa{\c{c}}{\~{a}}o participante e semin{\'{a}}rios},
author = {ENS, Romilda Teodora and Ploharski, Nara Regina and SALLES, Suely Therezinha Costa},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/dialogo-740.pdf:pdf},
journal = {Revista Di{\'{a}}logo Educacional},
keywords = {metodologia da pesquisa,pesquisa,pesquisa-a{\c{c}}{\~{a}}o,procedi- mentos,t{\'{e}}cnicas de pesquisa},
number = {4},
pages = {67--84},
title = {{a Pesquisa E O Fazer Pedag{\'{o}}gico : Gerar E DIFUNDIR CONHECIMENTOS}},
volume = {2},
year = {2001}
}
@book{RusselStuart.Norvig2013,
address = {Rio de Janeiro},
author = {{Russel, Stuart. Norvig}, Peter},
edition = {3{\textordfeminine}},
editor = {Ltda, Elsevier Editora},
file = {:home/tarcisio/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/Inteligencia Artificial{\_}3aEd{\_}Russell{\_}Stuart{\_}Norvig{\_} Peter.pdf:pdf},
isbn = {9780136042594},
title = {{Intelig{\^{e}}ncia Artificial}},
year = {2013}
}
@book{Mitchell1997,
abstract = {Um texto introdut{\'{o}}rio sobre abordagens prim{\'{a}}rias para a aprendizagem de m{\'{a}}quinas e o estudo de algoritmos de computador que melhoram automaticamente atrav{\'{e}}s da experi{\^{e}}ncia. Introduza conceitos b{\'{a}}sicos de estat{\'{i}}stica, intelig{\^{e}}ncia artificial, teoria da informa{\c{c}}{\~{a}}o e outras disciplinas, conforme necess{\'{a}}rio, com cobertura equilibrada de teoria e pr{\'{a}}tica e apresenta algoritmos importantes com ilustra{\c{c}}{\~{o}}es de seu uso. Inclui exerc{\'{i}}cios de cap{\'{i}}tulo. Conjuntos de dados on-line e implementa{\c{c}}{\~{o}}es de v{\'{a}}rios algoritmos est{\~{a}}o dispon{\'{i}}veis em um site. Nenhum conhecimento pr{\'{e}}vio em intelig{\^{e}}ncia artificial ou estat{\'{i}}stica {\'{e}} assumido. Para graduados avan{\c{c}}ados e estudantes de p{\'{o}}s-gradua{\c{c}}{\~{a}}o em inform{\'{a}}tica, engenharia, estat{\'{i}}stica e ci{\^{e}}ncias sociais, bem como profissionais de software.},
archivePrefix = {arXiv},
arxivId = {0-387-31073-8},
author = {Mitchell, Tom M.},
booktitle = {McGraw-Hill Science/Engineering/Math},
doi = {10.1007/978-3-540-75488-6_2},
eprint = {0-387-31073-8},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/McGrawHill{\_}-{\_}Machine{\_}Learning{\_}-Tom{\_}Mitchell.pdf:pdf},
isbn = {9781577354260},
issn = {10450823},
pages = {432},
pmid = {18292226},
publisher = {McGraw-Hill Science/Engineering/Math},
title = {{Machine learning}},
year = {1997}
}
@misc{Federal2016,
author = {Federal, Universidade and Piau{\'{i}}, D O and Propesq, Pr{\'{o}}-reitoria D E Pesquisa},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/Projeto DM-Peixe Boi.pdf:pdf},
title = {{Processo de Descoberta de Conhecimento em Base de Dados para previs{\~{a}}o de ocorr{\^{e}}ncias de Esp{\'{e}}cimes de Peixe Boi Marinho}},
year = {2016}
}
@article{Iria2009,
abstract = {We present an approach to automating knowledge extraction in the aerospace engineering domain which has had a fundamental impact on the way engineers manage their collective knowledge built with years of experience. Even though obtaining labelled data in this domain is hard due to the high cost of domain experts' time, the application of the machine learning-based technology was successful, yielding results comparable to the state-of-the-art. Moreover, we present a comparison between several machine learning approaches in extracting knowledge from reports about jet engines. We show that the application of a semi-supervised approach does not provide a significant increase in accuracy so as to justify its adoption due to its much higher computational cost, but that the application of a large-scale approach considerably reduces both training and testing time while keeping accuracy comparable to the standard supervised approach, making it a good choice for this class of application scenarios.},
author = {Iria, Jos{\'{e}}},
doi = {10.1145/1597735.1597753},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/p97-iria.pdf:pdf},
isbn = {9781605586588},
journal = {Proceedings of the fifth international conference on Knowledge capture - K-CAP '09},
keywords = {aerospace,information extraction,knowledge capture,machine learning},
pages = {97--104},
title = {{Automating knowledge capture in the aerospace domain}},
url = {http://dl.acm.org/citation.cfm?id=1597735.1597753},
year = {2009}
}
@phdthesis{LOPES2014,
abstract = {O problema de agrupamento (clustering) tem sido considerado como um dos problemas mais relevantes dentre aqueles existentes na {\'{a}}rea de pesquisa de aprendizagem n{\~{a}}o- supervisionada (sub{\'{a}}rea de Aprendizagem de M{\'{a}}quina). Embora o desenvolvimento e aprimoramento de algoritmos que solucionam esse problema tenha sido o principal foco de muitos pesquisadores o objetivo inicial se manteve obscuro: a compreens{\~{a}}o dos grupos formados. T{\~{a}}o importante quanto a identifica{\c{c}}{\~{a}}o dos grupos (clusters) {\'{e}} sua compreens{\~{a}}o e defini{\c{c}}{\~{a}}o. Uma boa defini{\c{c}}{\~{a}}o de um cluster representa um entendimento significativo e pode ajudar o especialista ao estudar ou interpretar dados. Frente ao problema de compreender clusters – isto {\'{e}}, de encontrar uma defini{\c{c}}{\~{a}}o ou em outras palavras, um r{\'{o}}tulo – este trabalho apresenta uma defini{\c{c}}{\~{a}}o para esse problema, deno- minado problema de rotula{\c{c}}{\~{a}}o, al{\'{e}}m de uma solu{\c{c}}{\~{a}}o baseada em t{\'{e}}cnicas com aprendi- zagem supervisionada, n{\~{a}}o-supervisionada e um modelo de discretiza{\c{c}}{\~{a}}o. Dessa forma, o problema {\'{e}} tratado desde sua concep{\c{c}}{\~{a}}o: o agrupamento de dados. Para isso, um m{\'{e}}todo com aprendizagem n{\~{a}}o-supervisionada {\'{e}} aplicado ao problema de clustering e ent{\~{a}}o um algoritmo com aprendizagem supervisionada ir{\'{a}} detectar quais atributos s{\~{a}}o relevantes para definir um dado cluster. Adicionalmente, algumas estrat{\'{e}}gias s{\~{a}}o utilizadas para formar uma metodologia que apresenta em sua totalidade um r{\'{o}}tulo (baseado em atributos e valores) para cada grupo fornecido. Finalmente, essa metodo- logia {\'{e}} aplicada em quatro bases de dados distintas apresentando bons resultados com uma m{\'{e}}dia acima de 93.5{\%} dos elementos rotulados corretamente..},
author = {LOPES, Lucas A.},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/dissertacao{\_}lopes.pdf:pdf},
keywords = {agrupamento,aprendizado de m{\'{a}}quina,rotula{\c{c}}{\~{a}}o},
mendeley-tags = {agrupamento,aprendizado de m{\'{a}}quina,rotula{\c{c}}{\~{a}}o},
pages = {73},
school = {Universidade Federal do Piau{\'{i}} - UFPI},
title = {{Rotula{\c{c}}{\~{a}}o Autom{\'{a}}tica de Grupos com Aprendizagem de M{\'{a}}quina Supervisionada}},
year = {2014}
}
@article{Tatibana,
author = {Tatibana, Cassia Yuri and Kaetsu, Deisi Yuki},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/classificacao{\_}automatica{\_}artigos{\_}utilizando{\_}redes{\_}neurais.pdf:pdf},
title = {{Redes Neurais}},
url = {http://www.din.uem.br/ia/neurais/{\#}bibliografia}
}
@phdthesis{Edmar1999,
author = {Edmar, Martineli},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/Tese{\_}Edmar.pdf:pdf},
pages = {1--104},
title = {{Extra{\c{c}}{\~{a}}o de conhecimento de redes neurais artificiais}},
year = {1999}
}
@article{Metodo2015,
abstract = {Na tarefa de classifica{\c{c}}{\~{a}}o utilizando algoritmos de aprendizado de m{\'{a}}quina, considera-se a exist{\^{e}}ncia de uma base de dados chamada conjunto de treinamento. Esse conjunto possui exemplos que s{\~{a}}o rotulados(pr{\'{e}}-classificados) e utilizados no treinamento do classificador. Deve ter um total de exemplos significativo e equilibrado para que, ap{\'{o}}s o treinamento, o classificador tenha um desempenho satisfat{\'{o}}rio. Por{\'{e}}m, na maioria dos casos reais, obter esse conjunto de treinamento com a quantidade de exemplos suficientes para induzir um classificador no treinamento pode ser oneroso, pois {\'{e}} necess{\'{a}}rio que seja realizada uma rotula{\c{c}}{\~{a}}o dos dados por um especialista no problema em quest{\~{a}}o. Exemplos n{\~{a}}o-rotulados s{\~{a}}o mais f{\'{a}}ceis de serem coletados em compara{\c{c}}{\~{a}}o aos que possuem r{\'{o}}tulos. A literatura mostra o interesse da comunidade cient{\'{i}}fica em uma nova abordagem de aprendizado chamada de semissupervisionada. Este tipo de aprendizado trabalha em um cen{\'{a}}rio em que existe um conjunto de dados rotulados, insuficiente para treinar um classificador, juntamente com um outro conjunto com dados n{\~{a}}o-rotulados, tamb{\'{e}}m, dispon{\'{i}}vel no treinamento. O objetivo do trabalho {\'{e}} propor um m{\'{e}}todo que visa rotular dados a partir de um pequeno conjunto rotulado. Esse m{\'{e}}todo combina um classificador e um agrupador para realizar a tarefa de classifica{\c{c}}{\~{a}}o de forma simples em rela{\c{c}}{\~{a}}o {\`{a}} outros m{\'{e}}todos encontrados na literatura. Foram realizados experimentos utilizando 5 bases de dados e os resultados comparados com os algoritmos co-training e k-meanski, que s{\~{a}}o outros algoritmos},
author = {LIMA, Bruno Vicente Alves},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/Disserta{\c{c}}{\~{a}}o - Bruno Vicente - UFPI-1-1.pdf:pdf},
keywords = {Semissupervisionado. Classifica{\c{c}}{\~{a}}o. Rotula{\c{c}}{\~{a}}o. Apr},
mendeley-tags = {Semissupervisionado. Classifica{\c{c}}{\~{a}}o. Rotula{\c{c}}{\~{a}}o. Apr},
title = {{M{\'{e}}todo Semissupervisionado de Rotula{\c{c}}{\~{a}}o e Classifica{\c{c}}{\~{a}}o Utilizando Agrupamento por Sementes e Classificadores}},
year = {2015}
}
@article{Steiner2007,
abstract = {A avalia{\c{c}}{\~{a}}o de risco de cr{\'{e}}dito {\'{e}} um importante problema administrativo da {\'{a}}rea de an{\'{a}}lise financeira. As Redes Neurais t{\^{e}}m recebido muita aten{\c{c}}{\~{a}}o pela sua alta taxa de acur{\'{a}}cia preditiva, no entanto n{\~{a}}o {\'{e}} f{\'{a}}cil compreender como elas alcan{\c{c}}am as suas decis{\~{o}}es. Neste artigo um conjunto de dados de cr{\'{e}}dito {\'{e}} analisado usando a t{\'{e}}cnica de extra{\c{c}}{\~{a}}o de regras NeuroRule e o software WEKA para a extra{\c{c}}{\~{a}}o de regras a partir de uma Rede Neural treinada. Os resultados foram considerados bastante satisfat{\'{o}}rios alcan{\c{c}}ando mais de 80{\%} de acur{\'{a}}cia quanto {\`{a}} concess{\~{a}}o (ou n{\~{a}}o) de cr{\'{e}}dito banc{\'{a}}rio em todas as simula{\c{c}}{\~{o}}es.},
author = {Steiner, Maria Teresinha Arns and Nievola, J{\'{u}}lio Cesar and Soma, Nei Yoshihiro and Shimizu, Tamio and {Steiner Neto}, Pedro Jos{\'{e}}},
doi = {10.1590/S0101-74382007000300002},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/v27n3a02{\_}regras{\_}rNA{\_}tomada{\_}decisao{\_}creditoBancario.pdf:pdf},
issn = {0101-7438},
journal = {Pesquisa Operacional},
pages = {407--426},
title = {{Extra{\c{c}}{\~{a}}o de regras de classifica{\c{c}}{\~{a}}o a partir de redes neurais para aux{\'{i}}lio {\`{a}} tomada de decis{\~{a}}o na concess{\~{a}}o de cr{\'{e}}dito banc{\'{a}}rio}},
url = {http://www.scielo.br/scielo.php?pid=S0101-74382007000300002{\&}script=sci{\_}arttext{\&}tlng=pt},
volume = {27},
year = {2007}
}
@article{Conduta2010,
author = {Conduta, Bruno Cust{\'{o}}dio and Magrin, Diego Henrique},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/2010{\_}IA{\_}FT{\_}UNICAMP{\_}aprendizagemMaquina.pdf:pdf},
isbn = {0070428077},
pages = {35},
title = {{Aprendizagem de M{\'{a}}quina}},
url = {http://www.ppgia.pucpr.br/{~}alekoe/AM/2012/6-kNN-AM-2012.pdf},
year = {2010}
}
