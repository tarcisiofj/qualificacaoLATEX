Automatically generated by Mendeley Desktop 1.17.13
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@misc{Catlett2006b,
address = {Springer, Berlin, Heidelberg},
author = {Catlett, J},
booktitle = {Kodratoff Y. (eds) Machine Learning — EWSL-91. EWSL 1991.},
doi = {https://doi.org/10.1007/BFb0017012},
file = {:home/tarcisio/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/carlet1991.pdf:pdf},
keywords = {discretisation,empirical concept learning,induction of decision trees},
pages = {164--178},
publisher = {Lecture Notes in Computer Science (Lecture Notes in Artificial Intelligence)},
title = {{On changing continuous attributes into ordered discrete attributes}},
volume = {482},
year = {1991}
}
@inproceedings{Pq,
abstract = {When modeling a probability distribution with a Bayesian network, we are faced with the problem of how to handle continuous variables. Most previous work has either solved the problem by discretizing, or assumed that the data are generated by a single Gaussian. In this paper we abandon the normality assumption and instead use statistical methods for nonparametric density estimation. For a naive Bayesian classifier, we present experimental results on a variety of natural and artificial domains, comparing two methods of density estimation: assuming normality and modeling each conditional distribution with a single Gaussian; and using nonparametric kernel density estimation. We observe large reductions in error on several natural and artificial data sets, which suggests that kernel estimation is a useful tool for learning Bayesian models.},
address = {Montr{\'{e}}al, Qu{\'{e}}, Canada},
author = {George, H. John and Langley, Pat},
booktitle = {UAI'95 Proceedings of the Eleventh conference on Uncertainty in artificial intelligence},
editor = {Besnard, Philippe (IRISA Rennes / France) and Hanks, Steve (University of Washington / Seattle)},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/artigo{\_}bayes-continuous.pdf:pdf},
keywords = {bayes},
mendeley-tags = {bayes},
pages = {338--345},
publisher = {Morgan Kalfmann Publishers},
title = {{Estimating Continuous Distributions in Bayesian Classifiers}},
url = {http://dl.acm.org/citation.cfm?id=2074158.2074196},
year = {1995}
}
@phdthesis{Madureira2017,
abstract = {Um grande n´ umero de mensagens curtas informais s˜ ao postadas dia- riamente em redes sociais, f´ orums de discuss˜ ao e pesquisas de satisfa¸ao. c˜ Emo¸oes parecem ser importantes de forma frequente nesses textos. O de- c˜ safio de identificar e entender a emo¸ao presente nesse tipo de comunica¸aoc˜ c˜ ´ e importante para distinguir o sentimento presente no texto e tamb´ em para identificar comportamentos anˆ omalos e inapropriados, eventualmente ofere- cendo algum tipo de risco. Este trabalho prop˜ oe a implementa¸ao de uma solu¸ao para a an´ c˜ c˜ alise de sentimento de textos curtos baseada em aprendizado por m´ aquina. Utili- zando t´ ecnicas de aprendizado supervisionado, ´ e desejado discernir se uma mensagem possui sentimento positivo, neutro ou negativo. As mensagens a serem analisadas ser˜ ao pesquisas de satisfa¸ao de servi¸ c˜ cos de TI. Foram uti- lizados nas an´ alises dois modelos, o primeiro modelo onde apenas o campo de texto livre ”Coment´ ario”foi considerado e o segundo modelo, onde al´ em do campo de texto livre ”Coment´ ario”, foram consideradas, adicionalmente, duas perguntas objetivas da pesquisa de satisfa¸ao. c˜ Os resultados obtidos indicam que as t´ ecnicas utilizadas de aprendizado por m´ aquina, n˜ ao ficam atr´ as dos resultados produzidos por aprendizado humano. A acur´ acia obtida foi de at´ e 86,8{\%}de acerto para ummodelo de trˆ es classes: ”elogio”, ”neutro”e ”reclama¸ao”. A acur´ c˜ acia foi significativamente superior, alcan¸ cando at´ e 94,5{\%} em um modelo alternativo, de apenas duas classes: ”elogio”e ”n˜ ao-elogio”},
address = {Rio de Janeiro},
author = {Madureira, Daniel Fialho},
file = {:root/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Madureira - 2017 - Analise de sentimento para textos curtos.pdf:pdf},
school = {Fundacao Getulio Vargas},
title = {{Analise de sentimento para textos curtos}},
year = {2017}
}
@article{Kumar2013,
abstract = {Clustering is the unsupervised classification of patterns (observations, data items, or feature vectors) into groups (clusters). The clustering problem has been addressed in many contexts and by researchers in many disciplines; this reflects its broad appeal and usefulness as one of the steps in exploratory data analysis. However, clustering is a difficult problem combinatorially, and differences in assumptions and contexts in different communities have made the transfer of useful generic concepts and methodologies slow to occur. This paper presents an overview of pattern clustering methods from a statistical pattern recognition perspective, with a goal of providing useful advice and references to fundamental concepts accessible to the broad community of clustering practitioners. We present a taxonomy of clustering techniques, and identify cross-cutting themes and recent advances. We also describe some important applications of clustering algorithms such as image segmentation, object recognition, and information retrieval. I.},
author = {Kumar, Ashok and Andu, Thavani and Thanamani, Antony Selvdoss},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/MultidimensionalClusteringMethods.pdf:pdf},
journal = {International Journal of Engineering Science Invention},
keywords = {cluster,data mining},
mendeley-tags = {cluster,data mining},
number = {7},
pages = {1--8},
title = {{Multidimensional Clustering Methods of Data Mining for Industrial Applications}},
volume = {2},
year = {2013}
}
@article{VonLuxburg2008,
abstract = {Statistical learning theory provides the theoretical basis for many of today's machine learning algorithms. In this article we attempt to give a gentle, non-technical overview over the key ideas and insights of statistical learning theory. We target at a broad audience, not necessarily machine learning researchers. This paper can serve as a starting point for people who want to get an overview on the field before diving into technical details.},
archivePrefix = {arXiv},
arxivId = {0810.4752},
author = {von Luxburg, Ulrike and Schoelkopf, Bernhard},
doi = {10.1016/B978-0-444-52936-7.50016-1},
eprint = {0810.4752},
file = {:home/tarcisio/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/statisticalLearningTheory.pdf:pdf},
issn = {18745857},
journal = {Learning},
pages = {1--40},
title = {{Statistical Learning Theory: Models, Concepts, and Results}},
url = {http://arxiv.org/abs/0810.4752},
year = {2008}
}
@article{Morasca2002,
abstract = {Classification trees have been successfully used in several application fields. However, continuous attributes cannot be used directly when building classification trees, but they must be first discretized with clustering techniques, which require some degree of subjectivity. We propose an approach to build classification trees that does not require the discretization of the continuous attributes. The approach is an extension of existing methods for building classification trees and is based on the information gain yielded by discrete and continuous attributes. Data from a software development case study are analyzed with both the proposed approach and C4.5 to show the approach's applicability and benefits over C4.5. Copyright 2002 ACM.},
author = {Morasca, Sandro and Chimiche, Scienze and Matematiche, Fisiche},
doi = {10.1145/568760.568832},
file = {:root/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Morasca, Chimiche, Matematiche - 2002 - A Proposal for Using Continuous Attributes in Classification Trees.pdf:pdf},
isbn = {1581135564},
keywords = {5,c4,continuous attributes,decision trees,id3},
pages = {0--7},
title = {{A Proposal for Using Continuous Attributes in Classification Trees}},
year = {2002}
}
@book{Bishop2013,
abstract = {The dramatic growth in practical applications for machine learning over the last ten years has been accompanied by many important developments in the underlying algorithms and techniques. For example, Bayesian methods have grown from a specialist niche to become mainstream, while graphical models have emerged as a general framework for describing and applying probabilistic techniques. The practical applicability of Bayesian methods has been greatly enhanced by the development of a range of approximate inference algorithms such as variational Bayes and expectation propagation, while new models based on kernels have had a significant impact on both algorithms and applications. This completely new textbook reflects these recent developments while providing a comprehensive introduction to the fields of pattern recognition and machine learning. It is aimed at advanced undergraduates or first-year PhD students, as well as researchers and practitioners. No previous knowledge of pattern recognition or machine learning concepts is assumed. Familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential as the book includes a self-contained introduction to basic probability theory. The book is suitable for courses on machine learning, statistics, computer science, signal processing, computer vision, data mining, and bioinformatics. Extensive support is provided for course instructors, including more than 400 exercises, graded according to difficulty. Example solutions for a subset of the exercises are available from the book web site, while solutions for the remainder can be obtained by instructors from the publisher. The book is supported by a great deal of additional material, and the reader is encouraged to visit the book web site for the latest information. Christopher M. Bishop is Deputy Director of Microsoft Research Cambridge, and holds a Chair in Computer Science at the University of Edinburgh. He is a Fellow of Darwin College Cambridge, a Fellow of the Royal Academy of Engineering, and a Fellow of the Royal Society of Edinburgh. His previous textbook "Neural Networks for Pattern Recognition" has been widely adopted.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Bishop, Christopher M},
booktitle = {Journal of Chemical Information and Modeling},
doi = {10.1117/1.2819119},
eprint = {arXiv:1011.1669v3},
isbn = {978-0-387-31073-2},
issn = {1098-6596},
number = {9},
pages = {1689--1699},
pmid = {25246403},
title = {{Pattern Recognition and Machine Learning}},
volume = {53},
year = {2013}
}
@phdthesis{Filho2015,
abstract = {O agrupamento (clustering) de dados tem sido considerado como um dos tópicos mais rele- vantes dentre aqueles existentes na área de aprendizagem de máquina não-supervisionada. Embora o desenvolvimento e aprimoramento de algoritmos que tratam esse problema tenham sido o principal foco de muitos pesquisadores, a compreensão da definição dos grupos (clusters) é tão importante quanto sua formação. Uma boa definição de um grupo pode ajudar na interpretação dos dados. Frente ao problema de compreender a definição dos grupos este trabalho descreve uma solução que utiliza a teoria de conjuntos fuzzy para identificar os elementos mais relevantes do agrupamento e modelar faixas de valores que sejam capazes de identificar cada um dos grupos, baseando-se em caracterı́sticas únicas. Os experimentos realizados demostram que o modelo proposto é bastante factı́vel e capaz de construir faixas de valores para a identificação dos grupos, assim como classificar novos elementos utilizando as definições fornecidas.},
author = {Filho, Vilmar P. R.},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/Quali Vilmar.pdf:pdf},
keywords = {Cluster,Fuzzy,Labeling,Learning (artificial intelligence)},
school = {Universidade Federal do Piau{\'{i}}},
title = {{Rotulação de grupos utilizando conjuntos fuzzy}},
year = {2015}
}
@book{Bishop2013,
abstract = {The dramatic growth in practical applications for machine learning over the last ten years has been accompanied by many important developments in the underlying algorithms and techniques. For example, Bayesian methods have grown from a specialist niche to become mainstream, while graphical models have emerged as a general framework for describing and applying probabilistic techniques. The practical applicability of Bayesian methods has been greatly enhanced by the development of a range of approximate inference algorithms such as variational Bayes and expectation propagation, while new models based on kernels have had a significant impact on both algorithms and applications. This completely new textbook reflects these recent developments while providing a comprehensive introduction to the fields of pattern recognition and machine learning. It is aimed at advanced undergraduates or first-year PhD students, as well as researchers and practitioners. No previous knowledge of pattern recognition or machine learning concepts is assumed. Familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential as the book includes a self-contained introduction to basic probability theory. The book is suitable for courses on machine learning, statistics, computer science, signal processing, computer vision, data mining, and bioinformatics. Extensive support is provided for course instructors, including more than 400 exercises, graded according to difficulty. Example solutions for a subset of the exercises are available from the book web site, while solutions for the remainder can be obtained by instructors from the publisher. The book is supported by a great deal of additional material, and the reader is encouraged to visit the book web site for the latest information. Christopher M. Bishop is Deputy Director of Microsoft Research Cambridge, and holds a Chair in Computer Science at the University of Edinburgh. He is a Fellow of Darwin College Cambridge, a Fellow of the Royal Academy of Engineering, and a Fellow of the Royal Society of Edinburgh. His previous textbook "Neural Networks for Pattern Recognition" has been widely adopted.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Bishop, Christopher M},
booktitle = {Journal of Chemical Information and Modeling},
doi = {10.1117/1.2819119},
eprint = {arXiv:1011.1669v3},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/Bishop - Pattern Recognition And Machine Learning - Springer  2006.pdf:pdf},
isbn = {978-0-387-31073-2},
issn = {1098-6596},
number = {9},
pages = {1689--1699},
pmid = {25246403},
title = {{Pattern Recognition and Machine Learning}},
volume = {53},
year = {2013}
}
@book{Mohri2012,
author = {Mohri, Mehryar and Rostamizadeh, Afshin and Talwalkar, Ameet},
file = {:home/tarcisio/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/Mehryar{\_}Mohri{\_}Afshin{\_}Rostamizadeh{\_}Ameet{\_}Talwalkar(BookFi.org).pdf:pdf},
isbn = {9780262018258},
title = {{Foundations Machine Learning}},
year = {2012}
}
@misc{LOPES2014,
abstract = {O problema de agrupamento (clustering) tem sido considerado como um dos problemas mais relevantes dentre aqueles existentes na {\'{a}}rea de pesquisa de aprendizagem n{\~{a}}o- supervisionada (sub{\'{a}}rea de Aprendizagem de M{\'{a}}quina). Embora o desenvolvimento e aprimoramento de algoritmos que solucionam esse problema tenha sido o principal foco de muitos pesquisadores o objetivo inicial se manteve obscuro: a compreens{\~{a}}o dos grupos formados. T{\~{a}}o importante quanto a identifica{\c{c}}{\~{a}}o dos grupos (clusters) {\'{e}} sua compreens{\~{a}}o e defini{\c{c}}{\~{a}}o. Uma boa defini{\c{c}}{\~{a}}o de um cluster representa um entendimento significativo e pode ajudar o especialista ao estudar ou interpretar dados. Frente ao problema de compreender clusters – isto {\'{e}}, de encontrar uma defini{\c{c}}{\~{a}}o ou em outras palavras, um r{\'{o}}tulo – este trabalho apresenta uma defini{\c{c}}{\~{a}}o para esse problema, deno- minado problema de rotula{\c{c}}{\~{a}}o, al{\'{e}}m de uma solu{\c{c}}{\~{a}}o baseada em t{\'{e}}cnicas com aprendi- zagem supervisionada, n{\~{a}}o-supervisionada e um modelo de discretiza{\c{c}}{\~{a}}o. Dessa forma, o problema {\'{e}} tratado desde sua concep{\c{c}}{\~{a}}o: o agrupamento de dados. Para isso, um m{\'{e}}todo com aprendizagem n{\~{a}}o-supervisionada {\'{e}} aplicado ao problema de clustering e ent{\~{a}}o um algoritmo com aprendizagem supervisionada ir{\'{a}} detectar quais atributos s{\~{a}}o relevantes para definir um dado cluster. Adicionalmente, algumas estrat{\'{e}}gias s{\~{a}}o utilizadas para formar uma metodologia que apresenta em sua totalidade um r{\'{o}}tulo (baseado em atributos e valores) para cada grupo fornecido. Finalmente, essa metodo- logia {\'{e}} aplicada em quatro bases de dados distintas apresentando bons resultados com uma m{\'{e}}dia acima de 93.5{\%} dos elementos rotulados corretamente..},
author = {LOPES, Lucas A.},
file = {:root/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/LOPES - 2014 - Rotula{\c{c}}{\~{a}}o Autom{\'{a}}tica de Grupos com Aprendizagem de M{\'{a}}quina Supervisionada.pdf:pdf},
institution = {Universidade Federal do Piau{\'{i}} - UFPI},
keywords = {agrupamento,aprendizado de m{\'{a}}quina,rotula{\c{c}}{\~{a}}o},
mendeley-tags = {agrupamento,aprendizado de m{\'{a}}quina,rotula{\c{c}}{\~{a}}o},
pages = {73},
title = {{Rotula{\c{c}}{\~{a}}o Autom{\'{a}}tica de Grupos com Aprendizagem de M{\'{a}}quina Supervisionada}},
type = {Disserta{\c{c}}{\~{a}}o (Mestrado em Ci{\^{e}}ncias da Computa{\c{c}}{\~{a}}o)},
year = {2014}
}
@book{Barber2011,
abstract = {Machine learning methods extract value from vast data sets quickly and with modest resources. They are established tools in a wide range of industrial applications, including search engines, DNA sequencing, stock market analysis, and robot locomotion, and their use is spreading rapidly. People who know the methods have their choice of rewarding jobs. This hands-on text opens these opportunities to computer science students with modest mathematical backgrounds. It is designed for final-year undergraduates and master's students with limited background in linear algebra and calculus. Comprehensive and coherent, it develops everything from basic reasoning to advanced techniques within the framework of graphical models. Students learn more than a menu of techniques, they develop analytical and problem-solving skills that equip them for the real world. Numerous examples and exercises, both computer based and theoretical, are included in every chapter. Resources for students and instructors, including a MATLAB toolbox, are available online.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Barber, David},
doi = {10.1017/CBO9780511804779},
eprint = {arXiv:1011.1669v3},
file = {:root/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barber - 2011 - Bayesian Reasoning and Machine Learning.pdf:pdf},
isbn = {9780511804779},
issn = {9780521518147},
pmid = {16931139},
title = {{Bayesian Reasoning and Machine Learning}},
url = {http://ebooks.cambridge.org/ref/id/CBO9780511804779},
year = {2011}
}
@article{Lorenzett2016,
author = {Lorenzett, Cassio dal Castel and Teloken, Alex},
file = {:root/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lorenzett, Teloken - 2016 - Estudo Comparativo entre os algoritmos de Minera{\c{c}}{\~{a}}o de Dados Random Forest e J48 na tomada de Decis{\~{a}}o.pdf:pdf},
journal = {Simp{\'{o}}sio de Pesquisa e Desenvolvimento em Computa{\c{c}}{\~{a}}o},
number = {1},
title = {{Estudo Comparativo entre os algoritmos de Minera{\c{c}}{\~{a}}o de Dados Random Forest e J48 na tomada de Decis{\~{a}}o}},
volume = {2},
year = {2016}
}
@article{Sanches2003,
abstract = {In order to apply machine learning classification algorithms, it is assumed that there exists a set of labeled data, called the training set, which is used to train the classifier. However, in real life, this training set may not contain enough labeled data to induce a good classifier. Recently, there has been much interest in a variant of this approach. This new approach, known as semi-supervised learning, assumes that, in addition to the labeled training data, there exists a second set of unlabeled data which is also available during training. One of the goals of semi-supervised learning is training classifiers when large amounts of unlabeled data are available together with a small amount of labeled data. The appeal of semi-supervised learning is due to the fact that in many real-world applications, such sets of unlabeled data are either readily available or inexpensive to collect compared to labeled data. Unlabeled data can often be collected by auto- mated means while labeled data requires human experts or other limited or expensive classification resources that may even be unfeasible in some cases. There are several ways in which unlabeled data can be used. In this work we explore one mechanism by which unlabeled data can be used to improve classification problems and propose a semi-supervised algorithm, called k-meanski, for using unlabeled data for supervised learning. There are two premises underlying the technique used by the proposed algorithm. The first is that input data falls naturally into clusters rather than being uniformly distributed across the entire input space. Furthermore, the initial input labeled data should fall near the center of the existing clusters in the input space. The second premise is that many of the points in some of these clusters belong to specific output categories. Obviously, the validity of these premises is dependent on the dataset used. The k-meanski algorithm works well when the data conform to both premises. If these assumptions are violated poor performance can result. Experiments using real world datasets where we randomly select a subset of the available data to act as labeled exemplars are shown.},
author = {Sanches, Marcelo Kaminski},
file = {:root/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sanches - 2003 - Aprendizado de m{\'{a}}quina semi-supervisionado proposta de um algoritmo para rotular exemplos a partir de poucos exemplos.pdf:pdf},
title = {{Aprendizado de m{\'{a}}quina semi-supervisionado: proposta de um algoritmo para rotular exemplos a partir de poucos exemplos rotulados}},
year = {2003}
}
@article{Chang2016,
author = {Chang, Shuo and Dai, Peng and Hong, Lichan and Sheng, Cheng and Zhang, Tianjiao and Chi, Ed H.},
doi = {10.1145/2856767.2856783},
file = {:root/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chang et al. - 2016 - AppGrouper Knowledge-graph-based Interactive Clustering Tool for Mobile App Search Results.pdf:pdf},
isbn = {9781450341370},
journal = {Proceedings of the 21st International Conference on Intelligent User Interfaces - IUI '16},
keywords = {clustering,interactive machine learning,search result clustering},
pages = {348--358},
title = {{AppGrouper: Knowledge-graph-based Interactive Clustering Tool for Mobile App Search Results}},
url = {http://dl.acm.org/citation.cfm?doid=2856767.2856783},
year = {2016}
}
@article{Quinlan1986,
abstract = {The technology for building knowledge-based systems by inductive inference from examples has been demonstrated successfully in several practical applications. This paper summarizes an approach to synthesizing decision trees that has been used in a variety of systems, and it describes one such system, ID3, in detail. Results from recent studies show ways in which the methodology can be modified to deal with information that is noisy and/or incomplete. A reported shortcoming of the basic algorithm is discussed and two means of overcoming it are compared. The paper concludes with illustrations of current research directions.},
author = {Quinlan, J. R.},
doi = {10.1023/A:1022643204877},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/quinlan.pdf:pdf},
isbn = {0885-6125},
issn = {15730565},
journal = {Machine Learning},
keywords = {classification,decision trees,expert systems,induction,information theory,knowledge acquisition},
number = {1},
pages = {81--106},
pmid = {17050186},
title = {{Induction of Decision Trees}},
volume = {1},
year = {1986}
}
@article{Hwang2002,
abstract = {A discretization technique converts continuous attribute values into discrete ones. Discretization is needed when classification algorithms require only discrete attributes. It is also useful to increase the speed and the accuracy of classification algorithms. This paper presents a dynamic discretization method, whose main characteristic is to detect interdependencies between all continuous attributes. Empirical evaluation on 12 datasets from the UCI repository shows that the proposed algorithm is a relatively effective method for discretization.},
author = {Hwang, Grace J and Li, Fumin},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/dynamicMethodforDiscretizationofContinuousAttributes.pdf:pdf},
isbn = {9783540440253},
issn = {16113349},
journal = {Lecture Notes in Computer Science - Intelligent Data Engineering and Automated Learning - IDEAL 2002: Third International Conference},
pages = {506},
title = {{A Dynamic Method for Discretization of Continuous Attributes}},
url = {http://www.springerlink.com/content/4n05b2n6x0cx4tlk},
volume = {2412/2002},
year = {2002}
}
@article{Kotsiantis2006,
abstract = {A discretization algorithm is needed in order to handle problems with real-valued attributes with Decision Trees (DTs), Bayesian Networks (BNs) and Rule-Learners (RLs), treating the resulting intervals as nominal val- ues. The performance of these systems is tied to the right election of these in- tervals. A good discretization algorithm has to balance the loss of information intrinsic to this kind of process and generating a reasonable number of cut points, that is, a reasonable search space. This paper presents the well known discretization techniques. Of course, a single article cannot be a complete re- view of all discretization algorithms. Despite this, we hope that the references cited cover the major theoretical issues and guide the researcher to interesting research directions and suggest possible combinations that have to be explored.},
author = {Kotsiantis, Sotiris and Kanellopoulos, Dimitris},
doi = {10.1016/B978-044452781-3/50006-2},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/discretizationTechniques.pdf:pdf},
isbn = {9780444527813},
journal = {GESTS International Transactions on Computer Science and Engineering},
number = {1},
pages = {47--58},
title = {{Discretization Techniques : A recent survey}},
volume = {32},
year = {2006}
}
@article{Steiner2006,
abstract = {A “Descoberta de Conhecimento em Bases de Dados” (Knowledge Discovery in Databases, KDD) {\'{e}} um processo composto de v{\'{a}}rias etapas, iniciando com a coleta de dados para o problema em pauta e finalizando com a interpreta- {\c{c}}{\~{a}}o e avalia{\c{c}}{\~{a}}o dos resultados obtidos. O presente trabalho objetiva mostrar a influ{\^{e}}ncia da an{\'{a}}lise explorat{\'{o}}ria dos dados no desempenho das t{\'{e}}cnicas de Minera{\c{c}}{\~{a}}o de Dados (Data Mining) quanto {\`{a}} classifica{\c{c}}{\~{a}}o de novos padr{\~{o}}es por meio da sua aplica{\c{c}}{\~{a}}o a um problema m{\'{e}}dico, al{\'{e}}m de comparar o desempenho delas entre si, visando obter a t{\'{e}}cnica com o maior percentual de acertos. Pelos resultados obtidos, pode-se concluir que a referida an{\'{a}}lise, se conduzida de forma adequada, pode trazer importantes melhorias nos desempenhos de quase todas as t{\'{e}}cnicas abor- dadas, tornando-se, assim, uma importante ferramenta para a otimiza{\c{c}}{\~{a}}o dos resultados finais. Para o problema em estudo, a t{\'{e}}cnica que envolve um modelo de Programa{\c{c}}{\~{a}}o Linear e uma outra que envolve Redes Neurais foram as t{\'{e}}cnicas que apresentaram os menores percentuais de erros para os conjuntos de testes, apresentando capacidades de generaliza{\c{c}}{\~{a}}o satisfat{\'{o}}rias.},
author = {Steiner, Maria Teresinha Arns MTA and Soma, Nei Yoshihiro NY and Shimizu, Tamio and Nievola, J{\'{u}}lio Cesar and steiner Neto, Pedro Jos{\'{e}}},
doi = {10.1590/S0104-530X2006000200013},
file = {:root/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Steiner et al. - 2006 - Abordagem de um problema m{\'{e}}dico por meio do processo de KDD com {\^{e}}nfase {\`{a}} an{\'{a}}lise explorat{\'{o}}ria dos dados.pdf:pdf},
issn = {0104-530X},
journal = {Gest{\~{a}}o {\&} Produ{\c{c}}{\~{a}}o},
keywords = {an{\'{a}}lise explorat{\'{o}}ria dos dados.,minera{\c{c}}{\~{a}}o de dados,processo KDD},
pages = {325--337},
title = {{Abordagem de um problema m{\'{e}}dico por meio do processo de KDD com {\^{e}}nfase {\`{a}} an{\'{a}}lise explorat{\'{o}}ria dos dados.}},
url = {http://www.scielo.br/scielo.php?script=sci{\_}arttext{\&}pid=S0104-530X2006000200013{\&}nrm=iso{\%}5Cnhttp://www.scielo.br/pdf/gp/v13n2/31177.pdf},
volume = {13},
year = {2006}
}
@article{Trandafili2012,
abstract = {Higher education institutions are overwhelmed with huge amounts of information regarding student's enrollment, number of courses completed, achievement in each course, performance indicators and other data. This has led to an increasingly complex analysis process of the growing volume of data and to the incapability to take decisions regarding curricula reform and restructuring. On the other side, educational data mining is a growing field aiming at discovering knowledge from student's data in order to thoroughly understand the learning process and take appropriate actions to improve the student's performance and the quality of the courses delivery. This paper presents a thorough analysis process performed on student's data through machine learning techniques. Experiments performed on a very large real-world dataset of students performance on all courses of a university, reveal interesting and important students profiles with clustering and surprising relationships among the courses performance with association},
author = {Trandafili, Evis and Allko{\c{c}}i, Alban and Kajo, Elinda and Xhuvani, Aleksand{\"{e}}r},
doi = {10.1145/2371316.2371350},
file = {:root/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Trandafili et al. - 2012 - Discovery and evaluation of student's profiles with machine learning.pdf:pdf},
isbn = {9781450312400},
journal = {Proceedings of the Fifth Balkan Conference in Informatics on - BCI '12},
pages = {174},
title = {{Discovery and evaluation of student's profiles with machine learning}},
url = {http://dl.acm.org/citation.cfm?doid=2371316.2371350},
year = {2012}
}
@article{Yohannes1999,
author = {Yohannes, Yisehac and Hoddinott, John},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/Pnach725{\_}CART.pdf:pdf},
pages = {1--29},
title = {{Classification and regression trees: an introduction}},
year = {1999}
}
@article{Lopes,
author = {Lopes, Lucas A and Machado, Vinicius P and Rabelo, Ricardo De A L},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/artigo{\_}lopes.pdf:pdf},
title = {{Automatic Labeling of Groupings through Supervised Machine Learning}}
}
@book{Mitchell1997,
abstract = {Um texto introdut{\'{o}}rio sobre abordagens prim{\'{a}}rias para a aprendizagem de m{\'{a}}quinas e o estudo de algoritmos de computador que melhoram automaticamente atrav{\'{e}}s da experi{\^{e}}ncia. Introduza conceitos b{\'{a}}sicos de estat{\'{i}}stica, intelig{\^{e}}ncia artificial, teoria da informa{\c{c}}{\~{a}}o e outras disciplinas, conforme necess{\'{a}}rio, com cobertura equilibrada de teoria e pr{\'{a}}tica e apresenta algoritmos importantes com ilustra{\c{c}}{\~{o}}es de seu uso. Inclui exerc{\'{i}}cios de cap{\'{i}}tulo. Conjuntos de dados on-line e implementa{\c{c}}{\~{o}}es de v{\'{a}}rios algoritmos est{\~{a}}o dispon{\'{i}}veis em um site. Nenhum conhecimento pr{\'{e}}vio em intelig{\^{e}}ncia artificial ou estat{\'{i}}stica {\'{e}} assumido. Para graduados avan{\c{c}}ados e estudantes de p{\'{o}}s-gradua{\c{c}}{\~{a}}o em inform{\'{a}}tica, engenharia, estat{\'{i}}stica e ci{\^{e}}ncias sociais, bem como profissionais de software.},
archivePrefix = {arXiv},
arxivId = {0-387-31073-8},
author = {Mitchell, Tom M.},
booktitle = {McGraw-Hill Science/Engineering/Math},
doi = {10.1007/978-3-540-75488-6_2},
eprint = {0-387-31073-8},
file = {:root/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mitchell - 1997 - Machine learning.pdf:pdf},
isbn = {9781577354260},
issn = {10450823},
pages = {432},
pmid = {18292226},
publisher = {McGraw-Hill Science/Engineering/Math},
title = {{Machine learning}},
year = {1997}
}
@article{Yang2011,
abstract = {Previous semi-supervised learning (SSL) techniques usually assume unlabeled data are relevant to the target task. That is, they follow the same distribution as the targeted labeled data. In this paper, we address a different and very difficult scenario in SSL, where the unlabeled data may be a mixture of data relevant or irrelevant to the target binary classification task. In our framework, we do not require explicitly prior knowledge on the relatedness of the unla- beled data to the target data. In order to alleviate the effect of the irrelevant unlabeled data and utilize the implicit knowledge among all available data, we develop a novel maximum margin classifier, named the tri-class support vector machine (3C-SVM), to seek an inductive rule to separate the target binary classification task well while finding out the irrelevant data by-product. To attain this goal, we introduce a new min loss function, which can relieve the impact of the irrelevant data while relying more on the labeled data and the relevant unlabeled data. This loss function can therefore achieve the maximum entropy principle. The 3C-SVM can then generalize standard SVMs, Semi-supervised SVMs, and SVMs learned from the universum as its special cases. We further analyze the proper- ty of 3C-SVM on why the irrelevant data can help to improve the model performance. For implementation, we make relaxation and approximate the objective by the convex-concave procedure, which turns the original optimization from integral programming problem to a problem by just solving a finite number of quadratic program- ming problems. Empirical results are reported to demonstrate the advantages of our 3C-SVM model.},
author = {Yang, Haiqin and Zhu, Shenghuo and King, Irwin and Lyu, Michael R.},
doi = {10.1145/2063576.2063711},
file = {:root/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2011 - Can irrelevant data help semi-supervised learning, why and how.pdf:pdf},
isbn = {9781450307178},
journal = {Proceedings of the 20th ACM international conference on Information and knowledge management - CIKM '11},
keywords = {att,com,irwin,previous semi-supervised learning,research,ssl,techniques usually assume,that is,they follow,to the target task,unlabeled data are relevant},
pages = {937},
title = {{Can irrelevant data help semi-supervised learning, why and how?}},
url = {http://dl.acm.org/citation.cfm?doid=2063576.2063711},
year = {2011}
}
@article{Mccallum1997,
author = {Mccallum, Andrew and Nigam, Kamal},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/multinomial-aaaiws98.pdf:pdf},
title = {{A Comparison of Event Models for Naive Bayes Text Classification}},
year = {1997}
}
@article{Iria2009,
abstract = {We present an approach to automating knowledge extraction in the aerospace engineering domain which has had a fundamental impact on the way engineers manage their collective knowledge built with years of experience. Even though obtaining labelled data in this domain is hard due to the high cost of domain experts' time, the application of the machine learning-based technology was successful, yielding results comparable to the state-of-the-art. Moreover, we present a comparison between several machine learning approaches in extracting knowledge from reports about jet engines. We show that the application of a semi-supervised approach does not provide a significant increase in accuracy so as to justify its adoption due to its much higher computational cost, but that the application of a large-scale approach considerably reduces both training and testing time while keeping accuracy comparable to the standard supervised approach, making it a good choice for this class of application scenarios.},
author = {Iria, Jos{\'{e}}},
doi = {10.1145/1597735.1597753},
file = {:root/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Iria - 2009 - Automating knowledge capture in the aerospace domain.pdf:pdf},
isbn = {9781605586588},
journal = {Proceedings of the fifth international conference on Knowledge capture - K-CAP '09},
keywords = {aerospace,information extraction,knowledge capture,machine learning},
pages = {97--104},
title = {{Automating knowledge capture in the aerospace domain}},
url = {http://dl.acm.org/citation.cfm?id=1597735.1597753},
year = {2009}
}
@article{Bruce2001,
author = {Bruce, RF},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/10.1.1.58.986.pdf:pdf},
journal = {Nlprs},
keywords = {Bayesian,semi-class},
title = {{A Bayesian Approach to Semi-Supervised Learning}},
url = {http://www.researchgate.net/publication/2930623{\_}A{\_}Bayesian{\_}Approach{\_}to{\_}Semi-Supervised{\_}Learning/file/9c96051b000243458e.pdf},
year = {2001}
}
@article{Dougherty1995,
abstract = {The objective of this case study was to obtain some first-hand information about the functional consequences of a cosmetic tongue split operation for speech and tongue motility. One male patient who had performed the operation on himself was interviewed and underwent a tongue motility assessment, as well as an ultrasound examination. Tongue motility was mildly reduced as a result of tissue scarring. Speech was rated to be fully intelligible and highly acceptable by 4 raters, although 2 raters noticed slight distortions of the sibilants /s/ and /z/. The 3-dimensional ultrasound demonstrated that the synergy of the 2 sides of the tongue was preserved. A notably deep posterior genioglossus furrow indicated compensation for the reduced length of the tongue blade. It is concluded that the tongue split procedure did not significantly affect the participant's speech intelligibility and tongue motility.},
archivePrefix = {arXiv},
arxivId = {arXiv:gr-qc/9809069v1},
author = {Dougherty, James and Kohavi, Ron and Sahami, Mehran},
doi = {10.1016/B978-1-55860-377-6.50032-3},
eprint = {9809069v1},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/supervisedUnsupervisedDiscretization.pdf:pdf},
isbn = {9780874216561},
issn = {0717-6163},
journal = {Machine Learning Proceedings 1995},
pages = {194--202},
pmid = {15003161},
primaryClass = {arXiv:gr-qc},
title = {{Supervised and Unsupervised Discretization of Continuous Features}},
url = {http://linkinghub.elsevier.com/retrieve/pii/B9781558603776500323},
volume = {0},
year = {1995}
}
@article{Steiner2007,
abstract = {A avalia{\c{c}}{\~{a}}o de risco de cr{\'{e}}dito {\'{e}} um importante problema administrativo da {\'{a}}rea de an{\'{a}}lise financeira. As Redes Neurais t{\^{e}}m recebido muita aten{\c{c}}{\~{a}}o pela sua alta taxa de acur{\'{a}}cia preditiva, no entanto n{\~{a}}o {\'{e}} f{\'{a}}cil compreender como elas alcan{\c{c}}am as suas decis{\~{o}}es. Neste artigo um conjunto de dados de cr{\'{e}}dito {\'{e}} analisado usando a t{\'{e}}cnica de extra{\c{c}}{\~{a}}o de regras NeuroRule e o software WEKA para a extra{\c{c}}{\~{a}}o de regras a partir de uma Rede Neural treinada. Os resultados foram considerados bastante satisfat{\'{o}}rios alcan{\c{c}}ando mais de 80{\%} de acur{\'{a}}cia quanto {\`{a}} concess{\~{a}}o (ou n{\~{a}}o) de cr{\'{e}}dito banc{\'{a}}rio em todas as simula{\c{c}}{\~{o}}es.},
author = {Steiner, Maria Teresinha Arns and Nievola, J{\'{u}}lio Cesar and Soma, Nei Yoshihiro and Shimizu, Tamio and {Steiner Neto}, Pedro Jos{\'{e}}},
doi = {10.1590/S0101-74382007000300002},
file = {:root/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Steiner et al. - 2007 - Extra{\c{c}}{\~{a}}o de regras de classifica{\c{c}}{\~{a}}o a partir de redes neurais para aux{\'{i}}lio {\`{a}} tomada de decis{\~{a}}o na conc.pdf:pdf},
issn = {0101-7438},
journal = {Pesquisa Operacional},
pages = {407--426},
title = {{Extra{\c{c}}{\~{a}}o de regras de classifica{\c{c}}{\~{a}}o a partir de redes neurais para aux{\'{i}}lio {\`{a}} tomada de decis{\~{a}}o na concess{\~{a}}o de cr{\'{e}}dito banc{\'{a}}rio}},
url = {http://www.scielo.br/scielo.php?pid=S0101-74382007000300002{\&}script=sci{\_}arttext{\&}tlng=pt},
volume = {27},
year = {2007}
}
@book{RusselStuart.Norvig2013,
address = {Rio de Janeiro},
author = {Russel, Stuart and Norvig, Peter},
edition = {3{\textordfeminine}},
editor = {Ltda, Elsevier Editora},
file = {:root/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Russel, Stuart. Norvig - 2013 - Intelig{\^{e}}ncia Artificial.pdf:pdf},
isbn = {9780136042594},
title = {{Intelig{\^{e}}ncia Artificial}},
year = {2013}
}
@article{ENS2001,
abstract = {O presente artigo relata a proposta na PUCPR de unir pesquisa e doc{\^{e}}ncia na forma{\c{c}}{\~{a}}o continuada de professores, mais especificamente dos estudos sobre a abordagem qualitativa e a metodologia da pesquisa que est{\'{a}} sendo utilizada no projeto Gest{\~{a}}o Estrat{\'{e}}gica de Compet{\^{e}}ncias e a Forma{\c{c}}{\~{a}}o do Professor. A realiza{\c{c}}{\~{a}}o da pesquisa vem propiciando ao grupo de professores da {\'{a}}rea de educa{\c{c}}{\~{a}}o um trabalho integrado, e ao mesmo tempo, um caminhar pela pes- quisa-a{\c{c}}{\~{a}}o, integrando os seguintes procedimentos e t{\'{e}}cnicas de pesquisa: an{\'{a}}- lise documental, an{\'{a}}lise iconogr{\'{a}}fica, aplica{\c{c}}{\~{a}}o de question{\'{a}}rios, entrevista semi-estruturada, observa{\c{c}}{\~{a}}o participante e semin{\'{a}}rios},
author = {ENS, Romilda Teodora and Ploharski, Nara Regina and SALLES, Suely Therezinha Costa},
file = {:root/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/ENS, Ploharski, SALLES - 2001 - a Pesquisa E O Fazer Pedag{\'{o}}gico Gerar E DIFUNDIR CONHECIMENTOS.pdf:pdf},
journal = {Revista Di{\'{a}}logo Educacional},
keywords = {metodologia da pesquisa,pesquisa,pesquisa-a{\c{c}}{\~{a}}o,procedi- mentos,t{\'{e}}cnicas de pesquisa},
number = {4},
pages = {67--84},
title = {{a Pesquisa E O Fazer Pedag{\'{o}}gico : Gerar E DIFUNDIR CONHECIMENTOS}},
volume = {2},
year = {2001}
}
@article{Raimundo2008,
author = {Raimundo, Lidiane Rosso and Mattos, Merisandra C{\^{o}}rtes De and Waleska, Priscyla},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/artigo{\_}CART{\_}unesc{\_}congresso.pdf:pdf},
keywords = {an{\'{a}}lise,armazenamento contribuiu para a,cart algorithm,classification,data mining,de dados,de tecnologias destinadas {\`{a}},decision trees,forma{\c{c}}{\~{a}}o de grandes reposit{\'{o}}rios,o avan{\c{c}}o computacional no,processamento e,que se refere ao,resumo,tornando-se necess{\'{a}}rio o desenvolvimento},
title = {{O Algoritmo de Classifica{\c{c}}{\~{a}}o CART em uma Ferramenta de Data Mining}},
year = {2008}
}
@phdthesis{Edmar1999,
author = {Edmar, Martineli},
file = {:root/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Edmar - 1999 - Extra{\c{c}}{\~{a}}o de conhecimento de redes neurais artificiais.pdf:pdf},
pages = {1--104},
title = {{Extra{\c{c}}{\~{a}}o de conhecimento de redes neurais artificiais}},
year = {1999}
}
@book{Wu2008,
abstract = {This paper presents the top 10 data mining algorithms identified by the IEEE International Conference on Data Mining (ICDM) in December 2006: C4.5, k-Means, SVM, Apriori, EM, PageRank, AdaBoost, k NN, Naive Bayes, and CART. These top 10 algorithms are among the most influential data mining algorithms in the research community. With each algorithm, we provide a description of the algorithm, discuss the impact of the algorithm, and review current and further research on the algorithm. These 10 algorithms cover classification, clustering, statistical learning, association analysis, and link mining, which are all among the most important topics in data mining research and development. {\textcopyright} Springer-Verlag London Limited 2007. },
author = {Wu, Xindong and Kumar, Vipin and Ross, Quinlan J. and Ghosh, Joydeep and Yang, Qiang and Motoda, Hiroshi and McLachlan, Geoffrey J. and Ng, Angus and Liu, Bing and Yu, Philip S. and Zhou, Zhi Hua and Steinbach, Michael and Hand, David J. and Steinberg, Dan},
booktitle = {Knowledge and Information Systems},
doi = {10.1007/s10115-007-0114-2},
file = {:root/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - 2008 - Top 10 algorithms in data mining.pdf:pdf},
isbn = {1011500701},
issn = {02191377},
number = {1},
pages = {1--37},
pmid = {25720841},
title = {{Top 10 algorithms in data mining}},
volume = {14},
year = {2008}
}
@article{Metodo2015,
abstract = {Na tarefa de classifica{\c{c}}{\~{a}}o utilizando algoritmos de aprendizado de m{\'{a}}quina, considera-se a exist{\^{e}}ncia de uma base de dados chamada conjunto de treinamento. Esse conjunto possui exemplos que s{\~{a}}o rotulados(pr{\'{e}}-classificados) e utilizados no treinamento do classificador. Deve ter um total de exemplos significativo e equilibrado para que, ap{\'{o}}s o treinamento, o classificador tenha um desempenho satisfat{\'{o}}rio. Por{\'{e}}m, na maioria dos casos reais, obter esse conjunto de treinamento com a quantidade de exemplos suficientes para induzir um classificador no treinamento pode ser oneroso, pois {\'{e}} necess{\'{a}}rio que seja realizada uma rotula{\c{c}}{\~{a}}o dos dados por um especialista no problema em quest{\~{a}}o. Exemplos n{\~{a}}o-rotulados s{\~{a}}o mais f{\'{a}}ceis de serem coletados em compara{\c{c}}{\~{a}}o aos que possuem r{\'{o}}tulos. A literatura mostra o interesse da comunidade cient{\'{i}}fica em uma nova abordagem de aprendizado chamada de semissupervisionada. Este tipo de aprendizado trabalha em um cen{\'{a}}rio em que existe um conjunto de dados rotulados, insuficiente para treinar um classificador, juntamente com um outro conjunto com dados n{\~{a}}o-rotulados, tamb{\'{e}}m, dispon{\'{i}}vel no treinamento. O objetivo do trabalho {\'{e}} propor um m{\'{e}}todo que visa rotular dados a partir de um pequeno conjunto rotulado. Esse m{\'{e}}todo combina um classificador e um agrupador para realizar a tarefa de classifica{\c{c}}{\~{a}}o de forma simples em rela{\c{c}}{\~{a}}o {\`{a}} outros m{\'{e}}todos encontrados na literatura. Foram realizados experimentos utilizando 5 bases de dados e os resultados comparados com os algoritmos co-training e k-meanski, que s{\~{a}}o outros algoritmos},
author = {LIMA, Bruno Vicente Alves},
file = {:root/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/LIMA - 2015 - M{\'{e}}todo Semissupervisionado de Rotula{\c{c}}{\~{a}}o e Classifica{\c{c}}{\~{a}}o Utilizando Agrupamento por Sementes e Classificadores.pdf:pdf},
keywords = {Semissupervisionado. Classifica{\c{c}}{\~{a}}o. Rotula{\c{c}}{\~{a}}o. Apr},
mendeley-tags = {Semissupervisionado. Classifica{\c{c}}{\~{a}}o. Rotula{\c{c}}{\~{a}}o. Apr},
title = {{M{\'{e}}todo Semissupervisionado de Rotula{\c{c}}{\~{a}}o e Classifica{\c{c}}{\~{a}}o Utilizando Agrupamento por Sementes e Classificadores}},
year = {2015}
}
@article{Carolina1999,
author = {Carolina, Maria and Cristiano, Ronaldo},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/Aprendizado{\_}de{\_}Maquina{\_}Simbolico{\_}para{\_}Mineracao.pdf:pdf},
title = {{Aprendizado de M{\'{a}}quina Simb{\'{o}}lico de Dados para Minera{\c{c}}{\~{a}}o}},
year = {1999}
}
@article{Tatibana,
author = {Tatibana, Cassia Yuri and Kaetsu, Deisi Yuki},
file = {:root/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tatibana, Kaetsu - Unknown - Redes Neurais.pdf:pdf},
title = {{Redes Neurais}},
url = {http://www.din.uem.br/ia/neurais/{\#}bibliografia}
}
@misc{Federal2016,
author = {Federal, Universidade and Piau{\'{i}}, D O and Propesq, Pr{\'{o}}-reitoria D E Pesquisa},
file = {:root/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Federal, Piau{\'{i}}, Propesq - 2016 - Processo de Descoberta de Conhecimento em Base de Dados para previs{\~{a}}o de ocorr{\^{e}}ncias de Esp{\'{e}}cimes d.pdf:pdf},
title = {{Processo de Descoberta de Conhecimento em Base de Dados para previs{\~{a}}o de ocorr{\^{e}}ncias de Esp{\'{e}}cimes de Peixe Boi Marinho}},
year = {2016}
}
@article{Lucca2013,
abstract = {Este artigo apresenta uma ferramenta para classifica{\c{c}}{\~{a}}o de texto baseada no algoritmo Na{\"{i}}ve Bayes. S{\~{a}}o descritos alguns conceitos b{\'{a}}sicos sobre classifica{\c{c}}{\~{a}}o textual na {\'{a}}rea Recupera{\c{c}}{\~{a}}o de Informa{\c{c}}{\~{o}}es, o algoritmo escolhido, um exemplo de utiliza{\c{c}}{\~{a}}o e a arquitetura da ferramenta.},
author = {Lucca, G and Pereira, I A and Prisco, A and Borges, E N},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/0019.pdf:pdf},
journal = {Centro de Ci{\^{e}}ncias Computacionais - Universidade Federal do Rio Grande (FURG) Rio Grande - RS - Brasil},
keywords = {naive bayes},
mendeley-tags = {naive bayes},
pages = {1--4},
title = {{Uma implementa{\c{c}}{\~{a}}o do algoritmo Na{\"{i}}ve Bayes para classifica{\c{c}}{\~{a}}o de texto}},
year = {2013}
}
@article{Domingos2012,
abstract = {MACHINE LEARNING SYSTEMS automatically learn programs from data. This is often a very attractive alternative to manually constructing them, and in the last decade the use of machine learning has spread rapidly throughout computer science and beyond. Machine learning is used in Web search, spam filters, recommender systems, ad placement, credit scoring, fraud detection, stock trading, drug design, and many other applications. A recent report from the McKinsey Global Institute asserts that machine learning (a.k.a. data mining or predictive analytics) will be the driver of the next big wave of innovation. Several fine textbooks are available to interested practitioners and researchers (for example, Mitchell and Witten et al.). However, much of the “folk knowledge” that is needed to successfully develop machine learning applications is not readily available in them. As a result, many machine learning projects take much longer than necessary or wind up producing less-than-ideal results. Yet much of this folk knowledge is fairly easy to communicate. This is the purpose of this article.},
archivePrefix = {arXiv},
arxivId = {cs/9605103},
author = {Domingos, Pedro},
doi = {10.1145/2347736.2347755},
eprint = {9605103},
file = {:root/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Domingos - 2012 - A few useful things to know about machine learning.pdf:pdf},
isbn = {0001-0782},
issn = {00010782},
journal = {Communications of the ACM},
number = {10},
pages = {78},
pmid = {1000183096},
primaryClass = {cs},
title = {{A few useful things to know about machine learning}},
url = {http://dl.acm.org/citation.cfm?doid=2347736.2347755},
volume = {55},
year = {2012}
}
@article{Monteiro2013,
author = {Monteiro, Felipe},
file = {:root/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Monteiro - 2013 - aplicados a Avalia{\c{c}}{\~{a}}o da Seguran{\c{c}}a Din{\^{a}}mica e.pdf:pdf},
number = {October},
title = {{aplicados a Avalia{\c{c}}{\~{a}}o da Seguran{\c{c}}a Din{\^{a}}mica e}},
year = {2013}
}
@dissertation{Filho2015,
abstract = {O agrupamento (clustering) de dados tem sido considerado como um dos tópicos mais rele- vantes dentre aqueles existentes na área de aprendizagem de máquina não-supervisionada. Embora o desenvolvimento e aprimoramento de algoritmos que tratam esse problema tenham sido o principal foco de muitos pesquisadores, a compreensão da definição dos grupos (clusters) é tão importante quanto sua formação. Uma boa definição de um grupo pode ajudar na interpretação dos dados. Frente ao problema de compreender a definição dos grupos este trabalho descreve uma solução que utiliza a teoria de conjuntos fuzzy para identificar os elementos mais relevantes do agrupamento e modelar faixas de valores que sejam capazes de identificar cada um dos grupos, baseando-se em caracterı́sticas únicas. Os experimentos realizados demostram que o modelo proposto é bastante factı́vel e capaz de construir faixas de valores para a identificação dos grupos, assim como classificar novos elementos utilizando as definições fornecidas.},
author = {Filho, Vilmar P R},
file = {:mnt/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/Quali Vilmar.pdf:pdf},
institution = {Universidade Federal do Piau{\'{i}}},
keywords = {Cluster,Fuzzy,Labeling,Learning (artificial intelligence)},
title = {{Rotulação de grupos utilizando conjuntos fuzzy}},
type = {Disserta{\c{c}}{\~{a}}o (Mestrado)},
year = {2015}
}
@book{Montgomery2013,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Montgomery, Karen},
booktitle = {Journal of Chemical Information and Modeling},
doi = {10.1017/CBO9781107415324.004},
edition = {1},
editor = {{O'Reilly Media}, Inc.},
eprint = {arXiv:1011.1669v3},
file = {:home/tarcisio/home{\_}zenwalk/tarcisio/Documentos/mestrado{\_}UFPI/dissertacao/build{\_}Dissertacao/Textos/artigos/big-data-now-2012.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {icle},
number = {9},
pages = {1689--1699},
pmid = {25246403},
publisher = {O'Reilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA 95472},
title = {{Big Data Now}},
volume = {53},
year = {2013}
}
@book{runkler2012,
title={Models and Algorithms for Intelligent Data Analysis},
author={Thomas A. Runkler},
isbn={978-3-658-14075-5},
series={Data Analytics},
publisher={Springer Vieweg},
year={2016},
edition={2},
copyright={Springer Fachmedien Wiesbaden}
}

@book{braiman1984,
  title={Classification and Regression Trees},
  series={Wadsworth Statistics/Probability},
  publisher={Chapman and Hall/CRC},
  author={Breiman, L. and Jerome H. Friedman and Richard A. Olshen and Charles J. Stone},
  edition={1},
  isbn={0412048418},
  year={1984},
}
@book{yohannes1999classification,
  title={Classification and Regression Trees, CART: A User Manual for Identifying Indicators of Vulnerability to Famine and Chronic Food Insecurity},
  author={Yohannes, Y. and Webb, P.},
  isbn={9780896293373},
  lccn={99022708},
  series={Microcomputers in policy research},
  url={https://books.google.com.br/books?id=7iuq4ikyNdoC},
  year={1999},
  publisher={International Food Policy Research Institute}
}
@article { kotsiantis2005logitboost,
  journal = "Informatica (Slovenia)",
  author = "Sotiris B Kotsiantis and Panayiotis E Pintelas",
  title = "Logitboost of Simple Bayesian Classifier",
  pages = "53",
  volume = "29",
  year = "2005",
} 

